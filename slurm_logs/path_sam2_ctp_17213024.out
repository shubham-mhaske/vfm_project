==============================================
Path-SAM2 + CTransPath Training
Job ID: 17213024
Node: g062
Start: Thu Nov 27 13:31:03 CST 2025
==============================================

name, memory.total [MiB]
NVIDIA A100-PCIE-40GB, 40960 MiB

Checking prerequisites...
✓ SAM2: sam2/checkpoints/sam2.1_hiera_large.pt
✓ CTransPath: models/ctranspath/ctranspath.pth
✓ BCSS dataset: 151 images

Configuration:
  Experiment: path_sam2_ctranspath
  Output: finetune_logs/path_sam2_ctranspath-17213024
  Fusion: concat (SAM2 256-dim + CTransPath 768-dim → 256-dim)
  GPU: Single A100 (WORLD_SIZE=1)

Starting training...
============================================================
PATH-SAM2 TRAINING (CTransPath)
SAM2 + CTransPath Fusion for Histopathology
============================================================

--- Configuration ---
experiment:
  name: path_sam2_ctranspath
ctranspath:
  checkpoint: models/ctranspath/ctranspath.pth
  freeze: false
  embed_dim: 768
  fusion_type: attention
scratch:
  resolution: 1024
  train_batch_size: 4
  num_train_workers: 8
  num_frames: 1
  max_num_objects: 3
  base_lr: 5.0e-05
  vision_lr: 5.0e-06
  phases_per_epoch: 1
  num_epochs: 50
  warmup_steps: 250
vos:
  train_transforms:
  - _target_: training.dataset.transforms.ComposeAPI
    transforms:
    - _target_: training.dataset.transforms.RandomHorizontalFlip
      consistent_transform: true
    - _target_: training.dataset.transforms.RandomVerticalFlip
      consistent_transform: true
    - _target_: training.dataset.transforms.RandomAffine
      degrees: 90
      consistent_transform: true
      num_tentatives: 2
    - _target_: training.dataset.transforms.RandomResizeAPI
      sizes: ${scratch.resolution}
      square: true
      consistent_transform: true
    - _target_: training.dataset.transforms.ColorJitter
      brightness: 0.15
      contrast: 0.15
      saturation: 0.15
      hue: 0.05
      consistent_transform: true
    - _target_: training.dataset.transforms.ToTensorAPI
    - _target_: training.dataset.transforms.NormalizeAPI
      mean:
      - 0.485
      - 0.456
      - 0.406
      std:
      - 0.229
      - 0.224
      - 0.225
trainer:
  _target_: training.trainer.Trainer
  mode: train_only
  max_epochs: ${times:${scratch.num_epochs},${scratch.phases_per_epoch}}
  accelerator: cuda
  seed_value: 42
  model:
    _target_: training.model.sam2.SAM2Train
    freeze_image_encoder: false
    image_encoder:
      _target_: sam2.modeling.backbones.image_encoder.ImageEncoder
      scalp: 1
      trunk:
        _target_: sam2.modeling.backbones.hieradet.Hiera
        embed_dim: 144
        num_heads: 2
        stages:
        - 2
        - 6
        - 36
        - 4
        global_att_blocks:
        - 23
        - 33
        - 43
        window_pos_embed_bkg_spatial_size:
        - 7
        - 7
        window_spec:
        - 8
        - 4
        - 16
        - 8
      neck:
        _target_: sam2.modeling.backbones.image_encoder.FpnNeck
        position_encoding:
          _target_: sam2.modeling.position_encoding.PositionEmbeddingSine
          num_pos_feats: 256
          normalize: true
          scale: null
          temperature: 10000
        d_model: 256
        backbone_channel_list:
        - 1152
        - 576
        - 288
        - 144
        fpn_top_down_levels:
        - 2
        - 3
        fpn_interp_model: nearest
    memory_attention:
      _target_: sam2.modeling.memory_attention.MemoryAttention
      d_model: 256
      pos_enc_at_input: true
      layer:
        _target_: sam2.modeling.memory_attention.MemoryAttentionLayer
        activation: relu
        dim_feedforward: 2048
        dropout: 0.1
        pos_enc_at_attn: false
        self_attention:
          _target_: sam2.modeling.sam.transformer.RoPEAttention
          rope_theta: 10000.0
          feat_sizes:
          - 64
          - 64
          embedding_dim: 256
          num_heads: 1
          downsample_rate: 1
          dropout: 0.1
        d_model: 256
        pos_enc_at_cross_attn_keys: true
        pos_enc_at_cross_attn_queries: false
        cross_attention:
          _target_: sam2.modeling.sam.transformer.RoPEAttention
          rope_theta: 10000.0
          feat_sizes:
          - 64
          - 64
          rope_k_repeat: true
          embedding_dim: 256
          num_heads: 1
          downsample_rate: 1
          dropout: 0.1
          kv_in_dim: 64
      num_layers: 4
    memory_encoder:
      _target_: sam2.modeling.memory_encoder.MemoryEncoder
      out_dim: 64
      position_encoding:
        _target_: sam2.modeling.position_encoding.PositionEmbeddingSine
        num_pos_feats: 64
        normalize: true
        scale: null
        temperature: 10000
      mask_downsampler:
        _target_: sam2.modeling.memory_encoder.MaskDownSampler
        kernel_size: 3
        stride: 2
        padding: 1
      fuser:
        _target_: sam2.modeling.memory_encoder.Fuser
        layer:
          _target_: sam2.modeling.memory_encoder.CXBlock
          dim: 256
          kernel_size: 7
          padding: 3
          layer_scale_init_value: 1.0e-06
          use_dwconv: true
        num_layers: 2
    num_maskmem: 7
    image_size: ${scratch.resolution}
    sigmoid_scale_for_mem_enc: 20.0
    sigmoid_bias_for_mem_enc: -10.0
    use_mask_input_as_output_without_sam: true
    directly_add_no_mem_embed: true
    no_obj_embed_spatial: true
    use_high_res_features_in_sam: true
    multimask_output_in_sam: true
    iou_prediction_use_sigmoid: true
    use_obj_ptrs_in_encoder: true
    add_tpos_enc_to_obj_ptrs: true
    proj_tpos_enc_in_obj_ptrs: true
    use_signed_tpos_enc_to_obj_ptrs: true
    only_obj_ptrs_in_the_past_for_eval: true
    pred_obj_scores: true
    pred_obj_scores_mlp: true
    fixed_no_obj_ptr: true
    multimask_output_for_tracking: true
    use_multimask_token_for_obj_ptr: true
    multimask_min_pt_num: 0
    multimask_max_pt_num: 1
    use_mlp_for_obj_ptr_proj: true
    explicit_prompt_type: ${trainer.data.train.datasets.0.video_dataset.prompt_type}
    prob_to_use_pt_input_for_train: 0.0
    prob_to_use_box_input_for_train: 0.0
    prob_to_sample_from_gt_for_train: 0.0
    num_frames_to_correct_for_train: 1
    num_frames_to_correct_for_eval: 1
    rand_frames_to_correct_for_train: false
    add_all_frames_to_correct_as_cond: false
    num_init_cond_frames_for_train: 1
    rand_init_cond_frames_for_train: false
    num_correction_pt_per_frame: 0
  data:
    train:
      _target_: training.dataset.sam2_datasets.TorchTrainMixedDataset
      phases_per_epoch: ${scratch.phases_per_epoch}
      batch_sizes:
      - ${scratch.train_batch_size}
      datasets:
      - _target_: training.dataset.vos_dataset.VOSDataset
        transforms: ${vos.train_transforms}
        training: true
        video_dataset:
          _target_: src.finetune_dataset.BCSSRawDataset
          img_folder: ${data_root}/images
          gt_folder: ${data_root}/masks
          split: train
          prompt_type: mixed
          use_neg_points: true
          num_points: 5
        sampler:
          _target_: training.dataset.vos_sampler.RandomUniformSampler
          num_frames: ${scratch.num_frames}
          max_num_objects: ${scratch.max_num_objects}
        multiplier: 1
      shuffle: true
      num_workers: ${scratch.num_train_workers}
      pin_memory: true
      drop_last: true
      collate_fn:
        _target_: training.utils.data_utils.collate_fn
        _partial_: true
        dict_key: all
  optim:
    amp:
      enabled: false
      amp_dtype: bfloat16
    optimizer:
      _target_: torch.optim.AdamW
    gradient_clip:
      _target_: training.optimizer.GradientClipper
      max_norm: 1.0
      norm_type: 2
    param_group_modifiers: []
    options:
      lr:
      - scheduler:
          _target_: fvcore.common.param_scheduler.CompositeParamScheduler
          schedulers:
          - _target_: fvcore.common.param_scheduler.LinearParamScheduler
            start_value: 0.0
            end_value: ${scratch.base_lr}
          - _target_: fvcore.common.param_scheduler.CosineParamScheduler
            start_value: ${scratch.base_lr}
            end_value: 1.0e-06
          lengths:
          - 0.15
          - 0.85
          interval_scaling:
          - rescaled
          - rescaled
      weight_decay:
      - scheduler:
          _target_: fvcore.common.param_scheduler.ConstantParamScheduler
          value: 0.02
  loss:
    all:
      _target_: training.loss_fns.MultiStepMultiMasksAndIous
      weight_dict:
        loss_mask: 5
        loss_dice: 3
        loss_iou: 1
        loss_class: 1
      supervise_all_iou: true
      iou_use_l1_loss: true
      pred_obj_scores: true
  distributed:
    backend: gloo
    find_unused_parameters: true
  logging:
    tensorboard_writer:
      _target_: training.utils.logger.make_tensorboard_logger
      log_dir: ${hydra:run.dir}/tensorboard
      flush_secs: 60
      should_log: true
    log_dir: ${hydra:run.dir}/logs
    log_freq: 20
  checkpoint:
    save_dir: ${hydra:run.dir}/checkpoints
    save_freq: 5
    model_weight_initializer:
      _partial_: true
      _target_: training.utils.checkpoint_utils.load_state_dict_into_model
      strict: false
      state_dict:
        _target_: training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels
        checkpoint_path: sam2/checkpoints/sam2.1_hiera_large.pt
        ckpt_state_dict_keys:
        - model
sam2_config_dir: sam2/sam2/configs
data_root: data/bcss
output_dir: finetune_logs
resume_checkpoint: null


Distributed Setup:
  RANK: 0
  WORLD_SIZE: 1
  LOCAL_RANK: 0

Patching trainer for single-GPU training...
  [CTransPath] Patched trainer to skip DDP

Instantiating trainer...
[2025-11-27 13:35:18,638][root][INFO] - Setting up torch.distributed with a timeout of 30 mins
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
INFO 2025-11-27 13:35:19,101 train_utils.py: 108: MACHINE SEED: 2100
INFO 2025-11-27 13:35:19,377 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-11-27 13:35:19,378 train_utils.py: 155: BASH_ENV=/sw/lmod/lmod/init/bash
BASH_FUNC_ml%%=() {  eval "$($LMOD_DIR/ml_cmd "$@")"
}
BASH_FUNC_module%%=() {  if [ -z "${LMOD_SH_DBG_ON+x}" ]; then
 case "$-" in 
 *v*x*)
 __lmod_sh_dbg='vx'
 ;;
 *v*)
 __lmod_sh_dbg='v'
 ;;
 *x*)
 __lmod_sh_dbg='x'
 ;;
 esac;
 fi;
 if [ -n "${__lmod_sh_dbg:-}" ]; then
 set +$__lmod_sh_dbg;
 echo "Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output" 1>&2;
 fi;
 eval "$($LMOD_CMD shell "$@")" && eval "$(${LMOD_SETTARG_CMD:-:} -s sh)";
 __lmod_my_status=$?;
 if [ -n "${__lmod_sh_dbg:-}" ]; then
 echo "Shell debugging restarted" 1>&2;
 set -$__lmod_sh_dbg;
 fi;
 unset __lmod_sh_dbg;
 return $__lmod_my_status
}
BASH_FUNC_which%%=() {  ( alias;
 eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --read-functions --show-tilde --show-dot $@
}
CMAKE_LIBRARY_PATH=/sw/eb/sw/OpenSSL/1.1/lib64:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib64:/sw/eb/sw/GCCcore/11.3.0/lib64
CMAKE_PREFIX_PATH=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1:/sw/eb/sw/CUDA/12.1.1:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0:/sw/eb/sw/OpenSSL/1.1:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0:/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0:/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0:/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0:/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0:/sw/eb/sw/binutils/2.38-GCCcore-11.3.0:/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0:/sw/eb/sw/GCCcore/11.3.0
CPATH=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1/include:/sw/eb/sw/CUDA/12.1.1/nvvm/include:/sw/eb/sw/CUDA/12.1.1/extras/CUPTI/include:/sw/eb/sw/CUDA/12.1.1/include:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/include:/sw/eb/sw/OpenSSL/1.1/include:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/include:/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/include:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/include:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/include:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/include:/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/include:/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/include:/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/include:/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/include:/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/include
CUDA_HOME=/sw/eb/sw/CUDA/12.1.1
CUDA_PATH=/sw/eb/sw/CUDA/12.1.1
CUDA_ROOT=/sw/eb/sw/CUDA/12.1.1
CUDA_VISIBLE_DEVICES=0
EBDEVELBINUTILS=/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-binutils-2.38-easybuild-devel
EBDEVELBZIP2=/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-bzip2-1.0.8-easybuild-devel
EBDEVELCUDA=/sw/eb/sw/CUDA/12.1.1/easybuild/Core-CUDA-12.1.1-easybuild-devel
EBDEVELCUDNN=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1/easybuild/Core-cuDNN-8.9.2.26-CUDA-12.1.1-easybuild-devel
EBDEVELGCCCORE=/sw/eb/sw/GCCcore/11.3.0/easybuild/Core-GCCcore-11.3.0-easybuild-devel
EBDEVELGMP=/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-GMP-6.2.1-easybuild-devel
EBDEVELLIBFFI=/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-libffi-3.4.2-easybuild-devel
EBDEVELLIBREADLINE=/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-libreadline-8.1.2-easybuild-devel
EBDEVELNCURSES=/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-ncurses-6.3-easybuild-devel
EBDEVELOPENSSL=/sw/eb/sw/OpenSSL/1.1/easybuild/Core-OpenSSL-1.1-easybuild-devel
EBDEVELPYTHON=/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-Python-3.10.4-easybuild-devel
EBDEVELSQLITE=/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-SQLite-3.38.3-easybuild-devel
EBDEVELTCL=/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-Tcl-8.6.12-easybuild-devel
EBDEVELXZ=/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-XZ-5.2.5-easybuild-devel
EBDEVELZLIB=/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/easybuild/Compiler-GCCcore-11.3.0-zlib-1.2.12-easybuild-devel
EBEXTSLISTPYTHON=wheel-0.37.1,setuptools-62.1.0,pip-22.0.4,blist-1.3.6,pbr-5.8.1,Cython-0.29.28,six-1.16.0,toml-0.10.2,flit-core-3.7.1,tomli-2.0.1,setuptools_scm-6.4.2,python-dateutil-2.8.2,decorator-5.1.1,liac-arff-2.5.0,pycrypto-2.6.1,ecdsa-0.17.0,ipaddress-1.0.23,asn1crypto-1.5.1,idna-3.3,pycparser-2.21,cffi-1.15.0,semantic_version-2.9.0,typing_extensions-4.2.0,setuptools-rust-1.3.0,cryptography-37.0.1,pyasn1-0.4.8,PyNaCl-1.5.0,bcrypt-3.2.2,paramiko-2.10.4,pyparsing-3.0.8,netifaces-0.11.0,netaddr-0.8.0,mock-4.0.3,pytz-2022.1,bitstring-3.1.9,appdirs-1.4.4,distlib-0.3.4,filelock-3.6.0,zipp-3.8.0,importlib_metadata-4.11.3,backports.entry_points_selectable-1.1.1,pathspec-0.9.0,pluggy-1.0.0,packaging-20.9,editables-0.3,platformdirs-2.4.1,scandir-1.10.0,pathlib2-2.3.7.post1,importlib_resources-5.7.1,virtualenv-20.14.1,docopt-0.6.2,joblib-1.1.0,chardet-4.0.0,certifi-2021.10.8,urllib3-1.26.9,charset-normalizer-2.0.12,requests-2.27.1,xlrd-2.0.1,py_expression_eval-0.3.14,tabulate-0.8.9,ujson-5.2.0,atomicwrites-1.4.0,py-1.11.0,more-itertools-8.12.0,attrs-21.4.0,backports.functools_lru_cache-1.6.4,wcwidth-0.2.5,iniconfig-1.1.1,colorama-0.4.4,pytest-7.1.2,MarkupSafe-2.1.1,Jinja2-3.1.2,sphinxcontrib-serializinghtml-1.1.5,sphinxcontrib-websupport-1.2.4,Pygments-2.12.0,imagesize-1.3.0,docutils-0.17.1,snowballstemmer-2.2.0,alabaster-0.7.12,sphinxcontrib-applehelp-1.0.2,sphinxcontrib-devhelp-1.0.2,sphinxcontrib-htmlhelp-2.0.0,sphinxcontrib-jsmath-1.0.1,sphinxcontrib-qthelp-1.0.3,Babel-2.10.1,Sphinx-4.5.0,sphinx-bootstrap-theme-0.8.1,click-8.1.3,psutil-5.9.0,future-0.18.2,sortedcontainers-2.4.0,intervaltree-3.1.0,pytoml-0.1.21,zipfile36-0.1.3,tomli_w-1.0.0,flit-3.7.1,regex-2022.4.24,intreehooks-1.0,pylev-1.4.0,pastel-0.2.1,crashtest-0.3.1,clikit-0.6.2,jeepney-0.8.0,SecretStorage-3.3.2,keyring-23.5.0,keyrings.alt-4.1.0,tomlkit-0.10.2,shellingham-1.4.0,requests-toolbelt-0.9.1,pyrsistent-0.18.1,pkginfo-1.8.2,ptyprocess-0.7.0,pexpect-4.8.0,jsonschema-4.4.0,simplejson-3.17.6,webencodings-0.5.1,html5lib-1.1,cleo-0.8.1,cachy-0.3.0,msgpack-1.0.3,CacheControl-0.12.11,lockfile-0.12.2,poetry-core-1.0.8,glob2-0.7,poetry-1.1.13,fsspec-2022.3.0,threadpoolctl-3.1.0,simplegeneric-0.8.1
EBROOTBINUTILS=/sw/eb/sw/binutils/2.38-GCCcore-11.3.0
EBROOTBZIP2=/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0
EBROOTCUDA=/sw/eb/sw/CUDA/12.1.1
EBROOTCUDNN=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1
EBROOTGCCCORE=/sw/eb/sw/GCCcore/11.3.0
EBROOTGMP=/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0
EBROOTLIBFFI=/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0
EBROOTLIBREADLINE=/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0
EBROOTNCURSES=/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0
EBROOTOPENSSL=/sw/eb/sw/OpenSSL/1.1
EBROOTPYTHON=/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0
EBROOTSQLITE=/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0
EBROOTTCL=/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0
EBROOTXZ=/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0
EBROOTZLIB=/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0
EBVERSIONBINUTILS=2.38
EBVERSIONBZIP2=1.0.8
EBVERSIONCUDA=12.1.1
EBVERSIONCUDNN=8.9.2.26
EBVERSIONGCCCORE=11.3.0
EBVERSIONGMP=6.2.1
EBVERSIONLIBFFI=3.4.2
EBVERSIONLIBREADLINE=8.1.2
EBVERSIONNCURSES=6.3
EBVERSIONOPENSSL=1.1
EBVERSIONPYTHON=3.10.4
EBVERSIONSQLITE=3.38.3
EBVERSIONTCL=8.6.12
EBVERSIONXZ=5.2.5
EBVERSIONZLIB=1.2.12
ENVIRONMENT=BATCH
FPATH=/sw/lmod/lmod/init/ksh_funcs
GPU_DEVICE_ORDINAL=0
HISTCONTROL=ignoredups
HISTSIZE=1000
HOME=/home/shubhammhaske
HOSTNAME=g062
HYDRA_BOOTSTRAP=slurm
HYDRA_LAUNCHER_EXTRA_ARGS=--external-launcher
I_MPI_HYDRA_BOOTSTRAP=slurm
I_MPI_HYDRA_BOOTSTRAP_EXEC_EXTRA_ARGS=--external-launcher
KRB5CCNAME=KCM:
LANG=en_US.UTF-8
LD_LIBRARY_PATH=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1/lib:/sw/eb/sw/CUDA/12.1.1/nvvm/lib64:/sw/eb/sw/CUDA/12.1.1/extras/CUPTI/lib64:/sw/eb/sw/CUDA/12.1.1/lib:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib:/sw/eb/sw/OpenSSL/1.1/lib64:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib64:/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/lib:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/lib:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/lib:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/lib:/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/lib:/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/lib:/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/lib:/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/lib:/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/lib:/sw/eb/sw/GCCcore/11.3.0/lib64
LESSOPEN=||/usr/bin/lesspipe.sh %s
LIBRARY_PATH=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1/lib:/sw/eb/sw/CUDA/12.1.1/stubs/lib64:/sw/eb/sw/CUDA/12.1.1/lib:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib:/sw/eb/sw/OpenSSL/1.1/lib64:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib64:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib:/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/lib:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/lib:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/lib:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/lib:/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/lib:/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/lib:/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/lib:/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/lib:/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/lib
LMOD_AVAIL_STYLE=system:<en_grouped>:fr_grouped
LMOD_CMD=/sw/lmod/lmod/libexec/lmod
LMOD_DIR=/sw/lmod/lmod/libexec
LMOD_PACKAGE_PATH=/sw/lmod/hprc/mods/
LMOD_PKG=/sw/lmod/lmod
LMOD_ROOT=/sw/lmod
LMOD_SETTARG_FULL_SUPPORT=no
LMOD_VERSION=8.7.59
LMOD_sys=Linux
LOADEDMODULES=GCCcore/11.3.0:zlib/1.2.12:binutils/2.38:bzip2/1.0.8:ncurses/6.3:libreadline/8.1.2:Tcl/8.6.12:SQLite/3.38.3:XZ/5.2.5:GMP/6.2.1:libffi/3.4.2:OpenSSL/1.1:Python/3.10.4:CUDA/12.1.1:cuDNN/8.9.2.26-CUDA-12.1.1
LOCAL_RANK=0
LOGNAME=shubhammhaske
LS_COLORS=rs=0:di=38;5;33:ln=38;5;51:mh=00:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=01;05;37;41:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;40:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.zst=38;5;9:*.tzst=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.wim=38;5;9:*.swm=38;5;9:*.dwm=38;5;9:*.esd=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.mjpg=38;5;13:*.mjpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.m4a=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.oga=38;5;45:*.opus=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
MAIL=/var/spool/mail/shubhammhaske
MANPATH=/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/share/man:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/share/man:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/share/man:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/share/man:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/share/man:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/man:/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/share/man:/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/share/man:/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/man:/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/share/man:/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/share/man:/sw/eb/sw/GCCcore/11.3.0/share/man:/sw/hprc/local/share/man:/sw/lmod/lmod/share/man::
MASTER_ADDR=localhost
MASTER_PORT=12355
MODULEPATH=/sw/eb/mods/all/Compiler/GCCcore/11.3.0:/sw/hprc/mods/all/Core:/sw/eb/mods/all/Core:/sw/lmod/hprc/mods/Linux:/sw/lmod/lmod/modulefiles/Core
MODULEPATH_ROOT=/sw/lmod/hprc/mods
MODULESHOME=/sw/lmod/lmod
NVIDIA_TF32_OVERRIDE=1
OLDPWD=/scratch/user/shubhammhaske/vfm_project
OMPI_MCA_plm_slurm_args=--external-launcher
OMP_NUM_THREADS=8
PATH=/scratch/user/shubhammhaske/vfm_env/bin:/sw/eb/sw/CUDA/12.1.1/nvvm/bin:/sw/eb/sw/CUDA/12.1.1/bin:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/bin:/sw/eb/sw/OpenSSL/1.1/bin:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/bin:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/bin:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/bin:/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/bin:/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/bin:/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/bin:/sw/eb/sw/GCCcore/11.3.0/bin:/scratch/user/shubhammhaske/vfm_env/bin:/sw/local/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/usr/lpp/mmfs/bin
PIP_CACHE_DIR=/scratch/user/shubhammhaske/PIP_CACHE
PKG_CONFIG_PATH=/sw/eb/sw/CUDA/12.1.1/pkgconfig:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/pkgconfig:/sw/eb/sw/OpenSSL/1.1/lib64/pkgconfig:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib/pkgconfig:/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/lib/pkgconfig:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/lib/pkgconfig:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/lib/pkgconfig:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/lib/pkgconfig:/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/lib/pkgconfig:/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/lib/pkgconfig:/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/lib/pkgconfig
PRTE_MCA_plm_slurm_args=--external-launcher
PS1=(vfm_env) 
PWD=/scratch/user/shubhammhaske/vfm_project
PYTHONPATH=/scratch/user/shubhammhaske/vfm_project:/scratch/user/shubhammhaske/vfm_project/sam2:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/easybuild/python:/scratch/user/shubhammhaske/vfm_project:/scratch/user/shubhammhaske/vfm_project/sam2
RANK=0
ROCR_VISIBLE_DEVICES=0
SACCT_FORMAT=jobid%10,jobname%20,user%20,ncpus%5,nnodes%6,state%20,elapsed%12s,start%20,end%20,reqmem%10,nodelist%-50
SCRATCH=/scratch/user/shubhammhaske
SHELL=/bin/bash
SHLVL=3
SINFO_FORMAT=%16P %6a %12l %11s %16F %20C
SLURMD_NODENAME=g062
SLURM_CLUSTER_NAME=grace
SLURM_CONF=/var/spool/slurmd/conf-cache/slurm.conf
SLURM_CPUS_ON_NODE=8
SLURM_CPUS_PER_TASK=8
SLURM_GPUS_ON_NODE=1
SLURM_GTIDS=0
SLURM_JOBID=17213024
SLURM_JOB_ACCOUNT=132730915297
SLURM_JOB_CPUS_PER_NODE=8
SLURM_JOB_END_TIME=1764358263
SLURM_JOB_GID=26467
SLURM_JOB_GPUS=1
SLURM_JOB_ID=17213024
SLURM_JOB_NAME=path_sam2_ctp
SLURM_JOB_NODELIST=g062
SLURM_JOB_NUM_NODES=1
SLURM_JOB_PARTITION=gpu
SLURM_JOB_QOS=normal
SLURM_JOB_START_TIME=1764271863
SLURM_JOB_UID=26467
SLURM_JOB_USER=shubhammhaske
SLURM_LOCALID=0
SLURM_MEM_PER_NODE=65536
SLURM_NNODES=1
SLURM_NODEID=0
SLURM_NODELIST=g062
SLURM_NPROCS=1
SLURM_NTASKS=1
SLURM_NTASKS_PER_NODE=1
SLURM_OOM_KILL_STEP=0
SLURM_PRIO_PROCESS=0
SLURM_PROCID=0
SLURM_SCRIPT_CONTEXT=prolog_task
SLURM_SUBMIT_DIR=/scratch/user/shubhammhaske/vfm_project
SLURM_SUBMIT_HOST=login1
SLURM_TASKS_PER_NODE=1
SLURM_TASK_PID=3365054
SLURM_TOPOLOGY_ADDR=core_r07.leaf_r14.g062
SLURM_TOPOLOGY_ADDR_PATTERN=switch.switch.node
SLURM_TRES_PER_TASK=cpu=8
SPRIO_FORMAT=%15i %16u %9r %.10Y %.10S %.10A %.10B %.10F %.10J %.10P %.10Q %40T
SQUEUE_FORMAT=%12A %20j %24u %22P %6D %5C %12T %12M %12L %16S  %24r %N
SSH_CLIENT=172.31.7.26 49637 22
SSH_CONNECTION=172.31.7.26 49637 128.194.35.39 22
SSH_TTY=/dev/pts/22
S_COLORS=auto
TERM=xterm-256color
TMPDIR=/tmp/job.17213024
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
USER=shubhammhaske
VIRTUAL_ENV=/scratch/user/shubhammhaske/vfm_env
VIRTUAL_ENV_PROMPT=(vfm_env) 
WORLD_SIZE=1
XDG_DATA_DIRS=/sw/eb/sw/CUDA/12.1.1/share:/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/share:/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/share:/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/share:/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/share:/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/share:/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/share:/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/share:/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/share:/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/share:/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/share:/sw/eb/sw/GCCcore/11.3.0/share
ZE_AFFINITY_MASK=0
_=/scratch/user/shubhammhaske/vfm_env/bin/python
_LMFILES_=/sw/eb/mods/all/Core/GCCcore/11.3.0.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/zlib/1.2.12.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/binutils/2.38.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/bzip2/1.0.8.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/ncurses/6.3.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/libreadline/8.1.2.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/Tcl/8.6.12.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/SQLite/3.38.3.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/XZ/5.2.5.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/GMP/6.2.1.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/libffi/3.4.2.lua:/sw/eb/mods/all/Core/OpenSSL/1.1.lua:/sw/eb/mods/all/Compiler/GCCcore/11.3.0/Python/3.10.4.lua:/sw/eb/mods/all/Core/CUDA/12.1.1.lua:/sw/eb/mods/all/Core/cuDNN/8.9.2.26-CUDA-12.1.1.lua
_ModuleTable001_=X01vZHVsZVRhYmxlXyA9IHsKTVR2ZXJzaW9uID0gMywKY19yZWJ1aWxkVGltZSA9IGZhbHNlLApjX3Nob3J0VGltZSA9IDAuMTI2NzI4MDU3ODYxMzMsCmRlcHRoVCA9IHt9LApmYW1pbHkgPSB7fSwKbVQgPSB7CkNVREEgPSB7CmZuID0gIi9zdy9lYi9tb2RzL2FsbC9Db3JlL0NVREEvMTIuMS4xLmx1YSIsCmZ1bGxOYW1lID0gIkNVREEvMTIuMS4xIiwKbG9hZE9yZGVyID0gMTQsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAwLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiQ1VEQS8xMi4xLjEiLAp3ViA9ICIwMDAwMDAwMTIuMDAwMDAwMDAxLjAwMDAwMDAwMS4qemZpbmFsIiwKfSwKR0NDY29yZSA9IHsKYWN0aW9uQSA9IHsKInByZXBlbmRfcGF0aChcIk1PRFVM
_ModuleTable002_=RVBBVEhcIixcIi9zdy9lYi9tb2RzL2FsbC9Db21waWxlci9HQ0Njb3JlLzExLjMuMFwiKSIsCn0sCmZuID0gIi9zdy9lYi9tb2RzL2FsbC9Db3JlL0dDQ2NvcmUvMTEuMy4wLmx1YSIsCmZ1bGxOYW1lID0gIkdDQ2NvcmUvMTEuMy4wIiwKbG9hZE9yZGVyID0gMSwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDAsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJHQ0Njb3JlLzExLjMuMCIsCndWID0gIjAwMDAwMDAxMS4wMDAwMDAwMDMuKnpmaW5hbCIsCn0sCkdNUCA9IHsKZm4gPSAiL3N3L2ViL21vZHMvYWxsL0NvbXBpbGVyL0dDQ2NvcmUvMTEuMy4wL0dNUC82LjIuMS5sdWEiLApmdWxsTmFtZSA9ICJHTVAvNi4yLjEiLApsb2FkT3JkZXIgPSAxMCwKcHJvcFQgPSB7
_ModuleTable003_=fSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJHTVAvNi4yLjEiLAp3ViA9ICIwMDAwMDAwMDYuMDAwMDAwMDAyLjAwMDAwMDAwMS4qemZpbmFsIiwKfSwKT3BlblNTTCA9IHsKZm4gPSAiL3N3L2ViL21vZHMvYWxsL0NvcmUvT3BlblNTTC8xLjEubHVhIiwKZnVsbE5hbWUgPSAiT3BlblNTTC8xLjEiLApsb2FkT3JkZXIgPSAxMiwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJPcGVuU1NMLzEuMSIsCndWID0gIjAwMDAwMDAwMS4wMDAwMDAwMDEuKnpmaW5hbCIsCn0sClB5dGhvbiA9IHsKZm4gPSAiL3N3L2ViL21vZHMvYWxsL0NvbXBpbGVyL0dDQ2NvcmUvMTEuMy4wL1B5dGhv
_ModuleTable004_=bi8zLjEwLjQubHVhIiwKZnVsbE5hbWUgPSAiUHl0aG9uLzMuMTAuNCIsCmxvYWRPcmRlciA9IDEzLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMCwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gIlB5dGhvbi8zLjEwLjQiLAp3ViA9ICIwMDAwMDAwMDMuMDAwMDAwMDEwLjAwMDAwMDAwNC4qemZpbmFsIiwKfSwKU1FMaXRlID0gewpmbiA9ICIvc3cvZWIvbW9kcy9hbGwvQ29tcGlsZXIvR0NDY29yZS8xMS4zLjAvU1FMaXRlLzMuMzguMy5sdWEiLApmdWxsTmFtZSA9ICJTUUxpdGUvMy4zOC4zIiwKbG9hZE9yZGVyID0gOCwKcHJvcFQgPSB7fSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJTUUxpdGUvMy4zOC4zIiwKd1YgPSAi
_ModuleTable005_=MDAwMDAwMDAzLjAwMDAwMDAzOC4wMDAwMDAwMDMuKnpmaW5hbCIsCn0sClRjbCA9IHsKZm4gPSAiL3N3L2ViL21vZHMvYWxsL0NvbXBpbGVyL0dDQ2NvcmUvMTEuMy4wL1RjbC84LjYuMTIubHVhIiwKZnVsbE5hbWUgPSAiVGNsLzguNi4xMiIsCmxvYWRPcmRlciA9IDcsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAyLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiVGNsLzguNi4xMiIsCndWID0gIjAwMDAwMDAwOC4wMDAwMDAwMDYuMDAwMDAwMDEyLip6ZmluYWwiLAp9LApYWiA9IHsKZm4gPSAiL3N3L2ViL21vZHMvYWxsL0NvbXBpbGVyL0dDQ2NvcmUvMTEuMy4wL1haLzUuMi41Lmx1YSIsCmZ1bGxOYW1lID0gIlhaLzUuMi41IiwKbG9hZE9yZGVyID0gOSwKcHJv
_ModuleTable006_=cFQgPSB7fSwKc3RhY2tEZXB0aCA9IDEsCnN0YXR1cyA9ICJhY3RpdmUiLAp1c2VyTmFtZSA9ICJYWi81LjIuNSIsCndWID0gIjAwMDAwMDAwNS4wMDAwMDAwMDIuMDAwMDAwMDA1Lip6ZmluYWwiLAp9LApiaW51dGlscyA9IHsKZm4gPSAiL3N3L2ViL21vZHMvYWxsL0NvbXBpbGVyL0dDQ2NvcmUvMTEuMy4wL2JpbnV0aWxzLzIuMzgubHVhIiwKZnVsbE5hbWUgPSAiYmludXRpbHMvMi4zOCIsCmxvYWRPcmRlciA9IDMsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAxLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAiYmludXRpbHMvMi4zOCIsCndWID0gIjAwMDAwMDAwMi4wMDAwMDAwMzguKnpmaW5hbCIsCn0sCmJ6aXAyID0gewpmbiA9ICIvc3cvZWIvbW9kcy9hbGwv
_ModuleTable007_=Q29tcGlsZXIvR0NDY29yZS8xMS4zLjAvYnppcDIvMS4wLjgubHVhIiwKZnVsbE5hbWUgPSAiYnppcDIvMS4wLjgiLApsb2FkT3JkZXIgPSA0LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMSwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImJ6aXAyLzEuMC44IiwKd1YgPSAiMDAwMDAwMDAxLjAwMDAwMDAwMC4wMDAwMDAwMDguKnpmaW5hbCIsCn0sCmN1RE5OID0gewpmbiA9ICIvc3cvZWIvbW9kcy9hbGwvQ29yZS9jdUROTi84LjkuMi4yNi1DVURBLTEyLjEuMS5sdWEiLApmdWxsTmFtZSA9ICJjdUROTi84LjkuMi4yNi1DVURBLTEyLjEuMSIsCmxvYWRPcmRlciA9IDE1LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMCwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJO
_ModuleTable008_=YW1lID0gImN1RE5OLzguOS4yLjI2LUNVREEtMTIuMS4xIiwKd1YgPSAiMDAwMDAwMDA4LjAwMDAwMDAwOS4wMDAwMDAwMDIuMDAwMDAwMDI2LipjdWRhLip6ZmluYWwtLjAwMDAwMDAxMi4wMDAwMDAwMDEuMDAwMDAwMDAxLip6ZmluYWwiLAp9LApsaWJmZmkgPSB7CmZuID0gIi9zdy9lYi9tb2RzL2FsbC9Db21waWxlci9HQ0Njb3JlLzExLjMuMC9saWJmZmkvMy40LjIubHVhIiwKZnVsbE5hbWUgPSAibGliZmZpLzMuNC4yIiwKbG9hZE9yZGVyID0gMTEsCnByb3BUID0ge30sCnN0YWNrRGVwdGggPSAxLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAibGliZmZpLzMuNC4yIiwKd1YgPSAiMDAwMDAwMDAzLjAwMDAwMDAwNC4wMDAwMDAwMDIuKnpmaW5hbCIsCn0sCmxp
_ModuleTable009_=YnJlYWRsaW5lID0gewpmbiA9ICIvc3cvZWIvbW9kcy9hbGwvQ29tcGlsZXIvR0NDY29yZS8xMS4zLjAvbGlicmVhZGxpbmUvOC4xLjIubHVhIiwKZnVsbE5hbWUgPSAibGlicmVhZGxpbmUvOC4xLjIiLApsb2FkT3JkZXIgPSA2LApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMSwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gImxpYnJlYWRsaW5lLzguMS4yIiwKd1YgPSAiMDAwMDAwMDA4LjAwMDAwMDAwMS4wMDAwMDAwMDIuKnpmaW5hbCIsCn0sCm5jdXJzZXMgPSB7CmZuID0gIi9zdy9lYi9tb2RzL2FsbC9Db21waWxlci9HQ0Njb3JlLzExLjMuMC9uY3Vyc2VzLzYuMy5sdWEiLApmdWxsTmFtZSA9ICJuY3Vyc2VzLzYuMyIsCmxvYWRPcmRlciA9IDUsCnByb3BUID0g
_ModuleTable010_=e30sCnN0YWNrRGVwdGggPSAyLApzdGF0dXMgPSAiYWN0aXZlIiwKdXNlck5hbWUgPSAibmN1cnNlcy82LjMiLAp3ViA9ICIwMDAwMDAwMDYuMDAwMDAwMDAzLip6ZmluYWwiLAp9LAp6bGliID0gewpmbiA9ICIvc3cvZWIvbW9kcy9hbGwvQ29tcGlsZXIvR0NDY29yZS8xMS4zLjAvemxpYi8xLjIuMTIubHVhIiwKZnVsbE5hbWUgPSAiemxpYi8xLjIuMTIiLApsb2FkT3JkZXIgPSAyLApwcm9wVCA9IHt9LApzdGFja0RlcHRoID0gMiwKc3RhdHVzID0gImFjdGl2ZSIsCnVzZXJOYW1lID0gInpsaWIvMS4yLjEyIiwKd1YgPSAiMDAwMDAwMDAxLjAwMDAwMDAwMi4wMDAwMDAwMTIuKnpmaW5hbCIsCn0sCn0sCm1wYXRoQSA9IHsKIi9zdy9lYi9tb2RzL2FsbC9Db21waWxlci9HQ0Nj
_ModuleTable011_=b3JlLzExLjMuMCIsICIvc3cvaHByYy9tb2RzL2FsbC9Db3JlIgosICIvc3cvZWIvbW9kcy9hbGwvQ29yZSIsICIvc3cvbG1vZC9ocHJjL21vZHMvTGludXgiLCAiL3N3L2xtb2QvbG1vZC9tb2R1bGVmaWxlcy9Db3JlIiwKfSwKc3lzdGVtQmFzZU1QQVRIID0gIi9zdy9ocHJjL21vZHMvYWxsL0NvcmU6L3N3L2ViL21vZHMvYWxsL0NvcmU6L3N3L2xtb2QvaHByYy9tb2RzL0xpbnV4Oi9zdy9sbW9kL2xtb2QvbW9kdWxlZmlsZXMvQ29yZSIsCn0K
_ModuleTable_Sz_=11
__LMOD_REF_COUNT_CMAKE_LIBRARY_PATH=/sw/eb/sw/OpenSSL/1.1/lib64:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib64:1;/sw/eb/sw/GCCcore/11.3.0/lib64:1
__LMOD_REF_COUNT_CMAKE_PREFIX_PATH=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1:1;/sw/eb/sw/CUDA/12.1.1:1;/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0:1;/sw/eb/sw/OpenSSL/1.1:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0:1;/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0:1;/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0:1;/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0:1;/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0:1;/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0:1;/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0:1;/sw/eb/sw/binutils/2.38-GCCcore-11.3.0:1;/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0:1;/sw/eb/sw/GCCcore/11.3.0:1
__LMOD_REF_COUNT_CPATH=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1/include:1;/sw/eb/sw/CUDA/12.1.1/nvvm/include:1;/sw/eb/sw/CUDA/12.1.1/extras/CUPTI/include:1;/sw/eb/sw/CUDA/12.1.1/include:1;/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/include:1;/sw/eb/sw/OpenSSL/1.1/include:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/include:1;/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/include:1;/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/include:1;/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/include:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/include:1;/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/include:1;/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/include:1;/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/include:1;/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/include:1;/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/include:1
__LMOD_REF_COUNT_LD_LIBRARY_PATH=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1/lib:1;/sw/eb/sw/CUDA/12.1.1/nvvm/lib64:1;/sw/eb/sw/CUDA/12.1.1/extras/CUPTI/lib64:1;/sw/eb/sw/CUDA/12.1.1/lib:1;/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib:1;/sw/eb/sw/OpenSSL/1.1/lib64:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib64:1;/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/lib:1;/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/lib:1;/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/lib:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/lib:1;/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/lib:1;/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/lib:1;/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/lib:1;/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/lib:1;/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/lib:1;/sw/eb/sw/GCCcore/11.3.0/lib64:1
__LMOD_REF_COUNT_LIBRARY_PATH=/sw/eb/sw/cuDNN/8.9.2.26-CUDA-12.1.1/lib:1;/sw/eb/sw/CUDA/12.1.1/stubs/lib64:1;/sw/eb/sw/CUDA/12.1.1/lib:1;/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib:1;/sw/eb/sw/OpenSSL/1.1/lib64:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib64:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib:1;/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/lib:1;/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/lib:1;/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/lib:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/lib:1;/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/lib:1;/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/lib:1;/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/lib:1;/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/lib:1;/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/lib:1
__LMOD_REF_COUNT_MANPATH=/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/share/man:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/share/man:1;/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/share/man:1;/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/share/man:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/share/man:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/man:1;/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/share/man:1;/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/share/man:1;/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/man:1;/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/share/man:1;/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/share/man:1;/sw/eb/sw/GCCcore/11.3.0/share/man:1;/sw/hprc/local/share/man:1;/sw/lmod/lmod/share/man:1;:1
__LMOD_REF_COUNT_MODULEPATH=/sw/eb/mods/all/Compiler/GCCcore/11.3.0:1;/sw/hprc/mods/all/Core:1;/sw/eb/mods/all/Core:1;/sw/lmod/hprc/mods/Linux:1;/sw/lmod/lmod/modulefiles/Core:1
__LMOD_REF_COUNT_PATH=/sw/eb/sw/CUDA/12.1.1/nvvm/bin:1;/sw/eb/sw/CUDA/12.1.1/bin:1;/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/bin:1;/sw/eb/sw/OpenSSL/1.1/bin:1;/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/bin:1;/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/bin:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/bin:1;/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/bin:1;/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/bin:1;/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/bin:1;/sw/eb/sw/GCCcore/11.3.0/bin:1;/scratch/user/shubhammhaske/vfm_env/bin:1;/sw/local/bin:1;/usr/local/bin:1;/usr/bin:1;/usr/local/sbin:1;/usr/sbin:1;/usr/lpp/mmfs/bin:1
__LMOD_REF_COUNT_PKG_CONFIG_PATH=/sw/eb/sw/CUDA/12.1.1/pkgconfig:1;/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/lib/pkgconfig:1;/sw/eb/sw/OpenSSL/1.1/lib64/pkgconfig:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/lib/pkgconfig:1;/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/lib/pkgconfig:1;/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/lib/pkgconfig:1;/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/lib/pkgconfig:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/lib/pkgconfig:1;/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/lib/pkgconfig:1;/sw/eb/sw/bzip2/1.0.8-GCCcore-11.3.0/lib/pkgconfig:1;/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/lib/pkgconfig:1
__LMOD_REF_COUNT_PYTHONPATH=/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/easybuild/python:1
__LMOD_REF_COUNT_XDG_DATA_DIRS=/sw/eb/sw/CUDA/12.1.1/share:1;/sw/eb/sw/Python/3.10.4-GCCcore-11.3.0/share:1;/sw/eb/sw/libffi/3.4.2-GCCcore-11.3.0/share:1;/sw/eb/sw/GMP/6.2.1-GCCcore-11.3.0/share:1;/sw/eb/sw/XZ/5.2.5-GCCcore-11.3.0/share:1;/sw/eb/sw/SQLite/3.38.3-GCCcore-11.3.0/share:1;/sw/eb/sw/Tcl/8.6.12-GCCcore-11.3.0/share:1;/sw/eb/sw/libreadline/8.1.2-GCCcore-11.3.0/share:1;/sw/eb/sw/ncurses/6.3-GCCcore-11.3.0/share:1;/sw/eb/sw/binutils/2.38-GCCcore-11.3.0/share:1;/sw/eb/sw/zlib/1.2.12-GCCcore-11.3.0/share:1;/sw/eb/sw/GCCcore/11.3.0/share:1
which_declare=declare -f

INFO 2025-11-27 13:35:19,378 trainer.py: 994: Setting up components: Model, loss, optim, meters etc.
INFO 2025-11-27 13:35:19,382 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: finetune_logs/path_sam2_ctranspath-17213024/tensorboard
INFO 2025-11-27 13:35:29,483 trainer.py:1064: ====================
INFO 2025-11-27 13:35:29,485 trainer.py:1065: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-11-27 13:35:29,488 trainer.py:1066: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 144, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0-1): 2 x MultiScaleBlock(
          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=144, out_features=432, bias=True)
            (proj): Linear(in_features=144, out_features=144, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=144, out_features=576, bias=True)
              (1): Linear(in_features=576, out_features=144, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=144, out_features=864, bias=True)
            (proj): Linear(in_features=288, out_features=288, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=288, out_features=1152, bias=True)
              (1): Linear(in_features=1152, out_features=288, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=144, out_features=288, bias=True)
        )
        (3-7): 5 x MultiScaleBlock(
          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=288, out_features=864, bias=True)
            (proj): Linear(in_features=288, out_features=288, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=288, out_features=1152, bias=True)
              (1): Linear(in_features=1152, out_features=288, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (8): MultiScaleBlock(
          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=288, out_features=1728, bias=True)
            (proj): Linear(in_features=576, out_features=576, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=576, out_features=2304, bias=True)
              (1): Linear(in_features=2304, out_features=576, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=288, out_features=576, bias=True)
        )
        (9-43): 35 x MultiScaleBlock(
          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=576, out_features=1728, bias=True)
            (proj): Linear(in_features=576, out_features=576, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=576, out_features=2304, bias=True)
              (1): Linear(in_features=2304, out_features=576, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (44): MultiScaleBlock(
          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=576, out_features=3456, bias=True)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=1152, out_features=4608, bias=True)
              (1): Linear(in_features=4608, out_features=1152, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=576, out_features=1152, bias=True)
        )
        (45-47): 3 x MultiScaleBlock(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=1152, out_features=4608, bias=True)
              (1): Linear(in_features=4608, out_features=1152, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
)
INFO 2025-11-27 13:35:29,489 trainer.py:1067: 	Total parameters 224 M
INFO 2025-11-27 13:35:29,489 trainer.py:1068: 	Trainable parameters 224 M
INFO 2025-11-27 13:35:29,489 trainer.py:1071: 	Non-Trainable parameters 0  
INFO 2025-11-27 13:35:29,489 trainer.py:1074: ====================
INFO 2025-11-27 13:35:29,574 trainer.py:1028: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-11-27 13:35:29,574 trainer.py: 319: Moving components to device cuda:0 and local rank 0.
INFO 2025-11-27 13:35:29,882 trainer.py: 325: Done moving components to device cuda:0 and local rank 0.
Using Nvidia CUDA backend.
Raw dataset length = 85
INFO 2025-11-27 13:36:10,687 sam2_datasets.py: 130: Dataset mixing probabilities: [1.0]
INFO 2025-11-27 13:36:15,180 trainer.py: 422: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': False, 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': 'sam2/checkpoints/sam2.1_hiera_large.pt', 'ckpt_state_dict_keys': ['model']}}
  [CTransPath] Skipping DDP wrapper for single-GPU training

✓ CTransPath checkpoint found: /scratch/user/shubhammhaske/vfm_project/models/ctranspath/ctranspath.pth

============================================================
Integrating CTransPath Encoder (Path-SAM2 Style)
============================================================
Original SAM2 encoder: ImageEncoder
Loading CTransPath from: /scratch/user/shubhammhaske/vfm_project/models/ctranspath/ctranspath.pth
  Using timm Swin architecture
Loading CTransPath weights from: /scratch/user/shubhammhaske/vfm_project/models/ctranspath/ctranspath.pth
  Loaded 158 tensors, skipped 42
  Missing: 13, Unexpected: 0
  CTransPath encoder initialized
  Using timm Swin architecture
Loading CTransPath weights from: /scratch/user/shubhammhaske/vfm_project/models/ctranspath/ctranspath.pth
  Loaded 158 tensors, skipped 42
  Missing: 13, Unexpected: 0
  CTransPath encoder initialized
  SAM2 encoder frozen

PathSAM2-CTransPath Encoder:
  Total parameters: 241,208,746
  Trainable parameters: 28,505,466
  Fusion type: attention

Parameter Summary:
  Total: 252,952,108
  Trainable: 40,248,828
  Frozen: 212,703,280
  Trainable %: 15.91%
============================================================

Configuring selective training...
  ✓ Unfreezing fusion (dimension_alignment)
  ✓ Unfreezing memory_attention
  ✓ Unfreezing memory_encoder
  ✓ Unfreezing sam_mask_decoder
  ✓ Unfreezing sam_prompt_encoder
  Total trainable: 12,514,353

============================================================
Starting Path-SAM2 (CTransPath) Training...
============================================================

WARNING 2025-11-27 13:36:51,119 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:37:46,102 train_utils.py: 278: Train Epoch: [0][ 0/21] | Batch Time: 74.99 (74.99) | Data Time: 16.75 (16.75) | Mem (GB): 21.00 (21.00/21.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 3.39e+01 (3.39e+01)
INFO 2025-11-27 13:38:22,144 train_utils.py: 278: Train Epoch: [0][20/21] | Batch Time: 0.30 (5.29) | Data Time: 0.00 (2.16) | Mem (GB): 9.00 (9.62/21.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 5.73e+01 (8.54e+01)
INFO 2025-11-27 13:38:22,233 trainer.py: 955: Estimated time remaining: 00d 01h 30m
INFO 2025-11-27 13:38:22,233 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:38:22,234 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 85.4082628885905, 'Losses/train_all_loss_mask': 15.794071401868548, 'Losses/train_all_loss_dice': 0.9565826796350025, 'Losses/train_all_loss_iou': 0.12759124700512206, 'Losses/train_all_loss_class': 3.440568115030016, 'Losses/train_all_core_loss': 85.4082628885905, 'Trainer/where': 0.019047619047619046, 'Trainer/epoch': 0, 'Trainer/steps_train': 21}
WARNING 2025-11-27 13:38:39,124 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:38:49,556 train_utils.py: 278: Train Epoch: [1][ 0/21] | Batch Time: 25.48 (25.48) | Data Time: 25.10 (25.10) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 7.16e+00 (7.16e+00)
WARNING 2025-11-27 13:39:23,596 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:40:13,836 train_utils.py: 278: Train Epoch: [1][20/21] | Batch Time: 0.30 (5.23) | Data Time: 0.00 (4.91) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 04m | Losses/train_all_loss: 4.49e+00 (2.90e+01)
INFO 2025-11-27 13:40:13,917 trainer.py: 955: Estimated time remaining: 00d 01h 27m
INFO 2025-11-27 13:40:13,917 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:40:13,917 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 29.043924604143417, 'Losses/train_all_loss_mask': 5.042717568931126, 'Losses/train_all_loss_dice': 0.910919155393328, 'Losses/train_all_loss_iou': 0.08063324505374544, 'Losses/train_all_loss_class': 1.0169456096917504, 'Losses/train_all_core_loss': 29.043924604143417, 'Trainer/where': 0.039047619047619046, 'Trainer/epoch': 1, 'Trainer/steps_train': 42}
WARNING 2025-11-27 13:40:23,176 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:40:37,377 train_utils.py: 278: Train Epoch: [2][ 0/21] | Batch Time: 21.59 (21.59) | Data Time: 21.20 (21.20) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 4.19e+00 (4.19e+00)
WARNING 2025-11-27 13:40:38,089 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:40:47,154 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:41:36,198 train_utils.py: 278: Train Epoch: [2][20/21] | Batch Time: 0.30 (3.83) | Data Time: 0.00 (3.51) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 2.54e+00 (7.36e+00)
INFO 2025-11-27 13:41:36,274 trainer.py: 955: Estimated time remaining: 00d 01h 02m
INFO 2025-11-27 13:41:36,274 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:41:36,274 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 7.360194989613125, 'Losses/train_all_loss_mask': 0.9461706436815716, 'Losses/train_all_loss_dice': 0.8119337558746338, 'Losses/train_all_loss_iou': 0.08253156021237373, 'Losses/train_all_loss_class': 0.11100882614337729, 'Losses/train_all_core_loss': 7.360194989613125, 'Trainer/where': 0.05904761904761905, 'Trainer/epoch': 2, 'Trainer/steps_train': 63}
INFO 2025-11-27 13:42:01,849 train_utils.py: 278: Train Epoch: [3][ 0/21] | Batch Time: 23.82 (23.82) | Data Time: 23.46 (23.46) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 06m | Losses/train_all_loss: 2.64e+00 (2.64e+00)
WARNING 2025-11-27 13:42:21,291 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:43:15,469 train_utils.py: 278: Train Epoch: [3][20/21] | Batch Time: 0.30 (4.64) | Data Time: 0.00 (4.32) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 2.47e+00 (2.64e+00)
INFO 2025-11-27 13:43:15,558 trainer.py: 955: Estimated time remaining: 00d 01h 14m
INFO 2025-11-27 13:43:15,559 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:43:15,559 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.639504841395787, 'Losses/train_all_loss_mask': 0.05248581387457393, 'Losses/train_all_loss_dice': 0.7760067525364104, 'Losses/train_all_loss_iou': 0.04757394435416375, 'Losses/train_all_loss_class': 0.0014815869122568497, 'Losses/train_all_core_loss': 2.639504841395787, 'Trainer/where': 0.07904761904761905, 'Trainer/epoch': 3, 'Trainer/steps_train': 84}
INFO 2025-11-27 13:43:42,720 train_utils.py: 278: Train Epoch: [4][ 0/21] | Batch Time: 25.36 (25.36) | Data Time: 24.97 (24.97) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 2.63e+00 (2.63e+00)
WARNING 2025-11-27 13:43:57,583 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:44:04,993 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:44:36,969 train_utils.py: 278: Train Epoch: [4][20/21] | Batch Time: 0.30 (3.79) | Data Time: 0.00 (3.47) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 2.51e+00 (2.62e+00)
INFO 2025-11-27 13:44:37,049 trainer.py: 955: Estimated time remaining: 00d 00h 59m
INFO 2025-11-27 13:44:37,049 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:44:37,050 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.621640829812913, 'Losses/train_all_loss_mask': 0.04808233341290837, 'Losses/train_all_loss_dice': 0.7788159535044715, 'Losses/train_all_loss_iou': 0.04408188441413499, 'Losses/train_all_loss_class': 0.0006994060444009435, 'Losses/train_all_core_loss': 2.621640829812913, 'Trainer/where': 0.09904761904761905, 'Trainer/epoch': 4, 'Trainer/steps_train': 105}
WARNING 2025-11-27 13:44:47,315 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:44:50,795 train_utils.py: 278: Train Epoch: [5][ 0/21] | Batch Time: 10.49 (10.49) | Data Time: 10.07 (10.07) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 09m | Losses/train_all_loss: 2.63e+00 (2.63e+00)
WARNING 2025-11-27 13:45:07,663 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:45:20,285 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:46:32,553 train_utils.py: 278: Train Epoch: [5][20/21] | Batch Time: 0.30 (5.35) | Data Time: 0.00 (5.03) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 2.57e+00 (2.57e+00)
INFO 2025-11-27 13:46:32,628 trainer.py: 955: Estimated time remaining: 00d 01h 22m
INFO 2025-11-27 13:46:32,629 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:46:32,630 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5698435306549072, 'Losses/train_all_loss_mask': 0.046409640017719495, 'Losses/train_all_loss_dice': 0.766026326588222, 'Losses/train_all_loss_iou': 0.03850453945675066, 'Losses/train_all_loss_class': 0.0012118512041918823, 'Losses/train_all_core_loss': 2.5698435306549072, 'Trainer/where': 0.11904761904761905, 'Trainer/epoch': 5, 'Trainer/steps_train': 126}
WARNING 2025-11-27 13:46:40,622 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:46:43,682 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:47:02,855 train_utils.py: 278: Train Epoch: [6][ 0/21] | Batch Time: 28.46 (28.46) | Data Time: 28.06 (28.06) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 11m | Losses/train_all_loss: 2.57e+00 (2.57e+00)
INFO 2025-11-27 13:48:17,600 train_utils.py: 278: Train Epoch: [6][20/21] | Batch Time: 0.30 (4.91) | Data Time: 0.00 (4.55) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 2.57e+00 (2.56e+00)
INFO 2025-11-27 13:48:17,682 trainer.py: 955: Estimated time remaining: 00d 01h 13m
INFO 2025-11-27 13:48:17,697 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:48:17,697 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5555567287263417, 'Losses/train_all_loss_mask': 0.046173357005630224, 'Losses/train_all_loss_dice': 0.7545846161388216, 'Losses/train_all_loss_iou': 0.06090080580629763, 'Losses/train_all_loss_class': 3.5286746353404454e-05, 'Losses/train_all_core_loss': 2.5555567287263417, 'Trainer/where': 0.13904761904761906, 'Trainer/epoch': 6, 'Trainer/steps_train': 147}
WARNING 2025-11-27 13:48:25,984 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:48:51,757 train_utils.py: 278: Train Epoch: [7][ 0/21] | Batch Time: 31.01 (31.01) | Data Time: 30.64 (30.64) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 13m | Losses/train_all_loss: 2.65e+00 (2.65e+00)
WARNING 2025-11-27 13:49:22,554 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:49:49,627 train_utils.py: 278: Train Epoch: [7][20/21] | Batch Time: 0.30 (4.23) | Data Time: 0.00 (3.91) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 2.40e+00 (2.55e+00)
INFO 2025-11-27 13:49:49,706 trainer.py: 955: Estimated time remaining: 00d 01h 02m
INFO 2025-11-27 13:49:49,707 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:49:49,707 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.549927280062721, 'Losses/train_all_loss_mask': 0.044784643997748695, 'Losses/train_all_loss_dice': 0.7521297789755321, 'Losses/train_all_loss_iou': 0.06956525173570428, 'Losses/train_all_loss_class': 4.9503979847566525e-05, 'Losses/train_all_core_loss': 2.549927280062721, 'Trainer/where': 0.15904761904761905, 'Trainer/epoch': 7, 'Trainer/steps_train': 168}
INFO 2025-11-27 13:50:25,850 train_utils.py: 278: Train Epoch: [8][ 0/21] | Batch Time: 34.29 (34.29) | Data Time: 33.92 (33.92) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 2.63e+00 (2.63e+00)
WARNING 2025-11-27 13:50:27,995 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:50:54,890 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:51:19,798 train_utils.py: 278: Train Epoch: [8][20/21] | Batch Time: 0.29 (4.20) | Data Time: 0.00 (3.88) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 2.51e+00 (2.57e+00)
INFO 2025-11-27 13:51:19,874 trainer.py: 955: Estimated time remaining: 00d 01h 00m
INFO 2025-11-27 13:51:19,875 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:51:19,875 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5731964906056723, 'Losses/train_all_loss_mask': 0.05174508069952329, 'Losses/train_all_loss_dice': 0.7368598324911935, 'Losses/train_all_loss_iou': 0.10388043611532166, 'Losses/train_all_loss_class': 1.1195603697941725e-05, 'Losses/train_all_core_loss': 2.5731964906056723, 'Trainer/where': 0.17904761904761904, 'Trainer/epoch': 8, 'Trainer/steps_train': 189}
INFO 2025-11-27 13:51:40,075 train_utils.py: 278: Train Epoch: [9][ 0/21] | Batch Time: 18.50 (18.50) | Data Time: 18.10 (18.10) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 2.60e+00 (2.60e+00)
WARNING 2025-11-27 13:51:53,495 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:52:21,954 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:52:50,212 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:52:51,943 train_utils.py: 278: Train Epoch: [9][20/21] | Batch Time: 0.30 (4.30) | Data Time: 0.00 (3.98) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 2.67e+00 (2.58e+00)
INFO 2025-11-27 13:52:52,023 trainer.py: 955: Estimated time remaining: 00d 01h 00m
INFO 2025-11-27 13:52:52,024 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:52:52,024 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5794288090297153, 'Losses/train_all_loss_mask': 0.04561642894432658, 'Losses/train_all_loss_dice': 0.7528379900114877, 'Losses/train_all_loss_iou': 0.09263229214896758, 'Losses/train_all_loss_class': 0.00020039956352338857, 'Losses/train_all_core_loss': 2.5794288090297153, 'Trainer/where': 0.19904761904761906, 'Trainer/epoch': 9, 'Trainer/steps_train': 210}
INFO 2025-11-27 13:53:12,175 train_utils.py: 278: Train Epoch: [10][ 0/21] | Batch Time: 15.84 (15.84) | Data Time: 15.49 (15.49) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 17m | Losses/train_all_loss: 2.57e+00 (2.57e+00)
WARNING 2025-11-27 13:53:31,846 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:54:05,053 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:54:22,375 train_utils.py: 278: Train Epoch: [10][20/21] | Batch Time: 0.30 (4.10) | Data Time: 0.00 (3.77) | Mem (GB): 9.00 (8.95/9.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 2.60e+00 (2.61e+00)
INFO 2025-11-27 13:54:22,455 trainer.py: 955: Estimated time remaining: 00d 00h 55m
INFO 2025-11-27 13:54:22,455 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:54:22,455 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.6096589111146473, 'Losses/train_all_loss_mask': 0.04537485841484297, 'Losses/train_all_loss_dice': 0.7483769768760318, 'Losses/train_all_loss_iou': 0.13752655684947968, 'Losses/train_all_loss_class': 0.00012712603422999308, 'Losses/train_all_core_loss': 2.6096589111146473, 'Trainer/where': 0.21904761904761905, 'Trainer/epoch': 10, 'Trainer/steps_train': 231}
WARNING 2025-11-27 13:54:38,751 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:54:45,562 train_utils.py: 278: Train Epoch: [11][ 0/21] | Batch Time: 21.24 (21.24) | Data Time: 20.83 (20.83) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 19m | Losses/train_all_loss: 2.59e+00 (2.59e+00)
WARNING 2025-11-27 13:54:50,437 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:55:52,026 train_utils.py: 278: Train Epoch: [11][20/21] | Batch Time: 0.30 (4.18) | Data Time: 0.00 (3.86) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 2.43e+00 (2.57e+00)
INFO 2025-11-27 13:55:52,100 trainer.py: 955: Estimated time remaining: 00d 00h 55m
INFO 2025-11-27 13:55:52,100 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:55:52,100 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5706568899608793, 'Losses/train_all_loss_mask': 0.045806627897989186, 'Losses/train_all_loss_dice': 0.7413104772567749, 'Losses/train_all_loss_iou': 0.1176387339475609, 'Losses/train_all_loss_class': 5.361251530950192e-05, 'Losses/train_all_core_loss': 2.5706568899608793, 'Trainer/where': 0.23904761904761906, 'Trainer/epoch': 11, 'Trainer/steps_train': 252}
INFO 2025-11-27 13:56:44,761 train_utils.py: 278: Train Epoch: [12][ 0/21] | Batch Time: 50.86 (50.86) | Data Time: 50.46 (50.46) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 21m | Losses/train_all_loss: 2.65e+00 (2.65e+00)
WARNING 2025-11-27 13:57:25,133 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:57:37,008 train_utils.py: 278: Train Epoch: [12][20/21] | Batch Time: 0.30 (4.91) | Data Time: 0.00 (4.60) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 2.47e+00 (2.54e+00)
INFO 2025-11-27 13:57:37,085 trainer.py: 955: Estimated time remaining: 00d 01h 03m
INFO 2025-11-27 13:57:37,085 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:57:37,085 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5437494913736978, 'Losses/train_all_loss_mask': 0.04511336201713199, 'Losses/train_all_loss_dice': 0.7292028466860453, 'Losses/train_all_loss_iou': 0.13057373215754828, 'Losses/train_all_loss_class': 3.897903290404176e-07, 'Losses/train_all_core_loss': 2.5437494913736978, 'Trainer/where': 0.259047619047619, 'Trainer/epoch': 12, 'Trainer/steps_train': 273}
WARNING 2025-11-27 13:58:01,900 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:58:14,189 train_utils.py: 278: Train Epoch: [13][ 0/21] | Batch Time: 35.06 (35.06) | Data Time: 34.64 (34.64) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 2.72e+00 (2.72e+00)
WARNING 2025-11-27 13:58:31,185 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:59:02,220 train_utils.py: 278: Train Epoch: [13][20/21] | Batch Time: 0.30 (3.96) | Data Time: 0.00 (3.64) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 23m | Losses/train_all_loss: 2.58e+00 (2.56e+00)
INFO 2025-11-27 13:59:02,299 trainer.py: 955: Estimated time remaining: 00d 00h 49m
INFO 2025-11-27 13:59:02,299 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 13:59:02,299 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5634062063126337, 'Losses/train_all_loss_mask': 0.04716476833536511, 'Losses/train_all_loss_dice': 0.7394318410328456, 'Losses/train_all_loss_iou': 0.10924922816810154, 'Losses/train_all_loss_class': 3.762027304557172e-05, 'Losses/train_all_core_loss': 2.5634062063126337, 'Trainer/where': 0.27904761904761904, 'Trainer/epoch': 13, 'Trainer/steps_train': 294}
WARNING 2025-11-27 13:59:20,326 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:59:24,779 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 13:59:26,153 train_utils.py: 278: Train Epoch: [14][ 0/21] | Batch Time: 21.97 (21.97) | Data Time: 21.59 (21.59) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 2.38e+00 (2.38e+00)
WARNING 2025-11-27 13:59:37,976 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 13:59:38,835 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:00:27,727 train_utils.py: 278: Train Epoch: [14][20/21] | Batch Time: 0.30 (3.98) | Data Time: 0.00 (3.66) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 2.64e+00 (2.53e+00)
INFO 2025-11-27 14:00:27,803 trainer.py: 955: Estimated time remaining: 00d 00h 48m
INFO 2025-11-27 14:00:27,803 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:00:27,803 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5309627510252453, 'Losses/train_all_loss_mask': 0.04838065696614129, 'Losses/train_all_loss_dice': 0.725526628040132, 'Losses/train_all_loss_iou': 0.1124718196335293, 'Losses/train_all_loss_class': 7.74755281385e-06, 'Losses/train_all_core_loss': 2.5309627510252453, 'Trainer/where': 0.29904761904761906, 'Trainer/epoch': 14, 'Trainer/steps_train': 315}
WARNING 2025-11-27 14:00:39,584 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:00:52,182 train_utils.py: 278: Train Epoch: [15][ 0/21] | Batch Time: 17.99 (17.99) | Data Time: 17.62 (17.62) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 2.47e+00 (2.47e+00)
WARNING 2025-11-27 14:00:54,355 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:01:16,499 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:02:32,321 train_utils.py: 278: Train Epoch: [15][20/21] | Batch Time: 0.30 (5.62) | Data Time: 0.00 (5.30) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 2.57e+00 (2.54e+00)
INFO 2025-11-27 14:02:32,405 trainer.py: 955: Estimated time remaining: 00d 01h 06m
INFO 2025-11-27 14:02:32,406 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:02:32,406 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.536580483118693, 'Losses/train_all_loss_mask': 0.04648864482130323, 'Losses/train_all_loss_dice': 0.7308735790706816, 'Losses/train_all_loss_iou': 0.11150701308534258, 'Losses/train_all_loss_class': 9.482537131462135e-06, 'Losses/train_all_core_loss': 2.536580483118693, 'Trainer/where': 0.319047619047619, 'Trainer/epoch': 15, 'Trainer/steps_train': 336}
WARNING 2025-11-27 14:02:52,388 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:02:57,669 train_utils.py: 278: Train Epoch: [16][ 0/21] | Batch Time: 23.47 (23.47) | Data Time: 23.12 (23.12) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 2.49e+00 (2.49e+00)
WARNING 2025-11-27 14:03:01,264 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:03:04,423 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:03:13,604 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:04:33,409 train_utils.py: 278: Train Epoch: [16][20/21] | Batch Time: 0.29 (5.68) | Data Time: 0.00 (5.37) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 2.51e+00 (2.52e+00)
INFO 2025-11-27 14:04:33,491 trainer.py: 955: Estimated time remaining: 00d 01h 05m
INFO 2025-11-27 14:04:33,492 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:04:33,492 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.521732875279018, 'Losses/train_all_loss_mask': 0.047080213470118384, 'Losses/train_all_loss_dice': 0.7283127563340324, 'Losses/train_all_loss_iou': 0.10138831145706631, 'Losses/train_all_loss_class': 5.2313549198762785e-06, 'Losses/train_all_core_loss': 2.521732875279018, 'Trainer/where': 0.33904761904761904, 'Trainer/epoch': 16, 'Trainer/steps_train': 357}
INFO 2025-11-27 14:05:16,258 train_utils.py: 278: Train Epoch: [17][ 0/21] | Batch Time: 40.97 (40.97) | Data Time: 40.60 (40.60) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 2.48e+00 (2.48e+00)
WARNING 2025-11-27 14:05:18,300 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:05:29,365 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:06:05,906 train_utils.py: 278: Train Epoch: [17][20/21] | Batch Time: 0.30 (4.32) | Data Time: 0.00 (4.00) | Mem (GB): 9.00 (8.95/9.00) | Time Elapsed: 00d 00h 30m | Losses/train_all_loss: 2.46e+00 (2.48e+00)
INFO 2025-11-27 14:06:05,993 trainer.py: 955: Estimated time remaining: 00d 00h 48m
INFO 2025-11-27 14:06:05,994 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:06:05,994 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.484310365858532, 'Losses/train_all_loss_mask': 0.04542706126258487, 'Losses/train_all_loss_dice': 0.711848897593362, 'Losses/train_all_loss_iou': 0.12162712713082631, 'Losses/train_all_loss_class': 1.2344854910396555e-06, 'Losses/train_all_core_loss': 2.484310365858532, 'Trainer/where': 0.35904761904761906, 'Trainer/epoch': 17, 'Trainer/steps_train': 378}
INFO 2025-11-27 14:06:21,927 train_utils.py: 278: Train Epoch: [18][ 0/21] | Batch Time: 14.14 (14.14) | Data Time: 13.77 (13.77) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 2.37e+00 (2.37e+00)
WARNING 2025-11-27 14:06:26,921 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:07:40,337 train_utils.py: 278: Train Epoch: [18][20/21] | Batch Time: 0.30 (4.41) | Data Time: 0.00 (4.09) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 2.69e+00 (2.52e+00)
INFO 2025-11-27 14:07:40,419 trainer.py: 955: Estimated time remaining: 00d 00h 47m
INFO 2025-11-27 14:07:40,419 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:07:40,420 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5151368095761253, 'Losses/train_all_loss_mask': 0.04497429568852697, 'Losses/train_all_loss_dice': 0.7291358737718492, 'Losses/train_all_loss_iou': 0.10284687144060929, 'Losses/train_all_loss_class': 1.08772824126109e-05, 'Losses/train_all_core_loss': 2.5151368095761253, 'Trainer/where': 0.3790476190476191, 'Trainer/epoch': 18, 'Trainer/steps_train': 399}
WARNING 2025-11-27 14:07:48,952 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:08:09,352 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:08:12,217 train_utils.py: 278: Train Epoch: [19][ 0/21] | Batch Time: 29.99 (29.99) | Data Time: 29.63 (29.63) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 32m | Losses/train_all_loss: 2.56e+00 (2.56e+00)
INFO 2025-11-27 14:09:07,874 train_utils.py: 278: Train Epoch: [19][20/21] | Batch Time: 0.30 (4.08) | Data Time: 0.00 (3.75) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 2.49e+00 (2.50e+00)
INFO 2025-11-27 14:09:07,952 trainer.py: 955: Estimated time remaining: 00d 00h 42m
INFO 2025-11-27 14:09:07,952 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:09:07,952 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.501793997628348, 'Losses/train_all_loss_mask': 0.04894613297212692, 'Losses/train_all_loss_dice': 0.7047365847088042, 'Losses/train_all_loss_iou': 0.14285329835755484, 'Losses/train_all_loss_class': 2.741870565063708e-07, 'Losses/train_all_core_loss': 2.501793997628348, 'Trainer/where': 0.39904761904761904, 'Trainer/epoch': 19, 'Trainer/steps_train': 420}
WARNING 2025-11-27 14:09:18,250 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:09:35,389 train_utils.py: 278: Train Epoch: [20][ 0/21] | Batch Time: 24.05 (24.05) | Data Time: 23.67 (23.67) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 2.53e+00 (2.53e+00)
WARNING 2025-11-27 14:09:46,015 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:10:17,077 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:10:35,489 train_utils.py: 278: Train Epoch: [20][20/21] | Batch Time: 0.30 (4.01) | Data Time: 0.00 (3.69) | Mem (GB): 9.00 (8.95/9.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 2.65e+00 (2.51e+00)
INFO 2025-11-27 14:10:35,579 trainer.py: 955: Estimated time remaining: 00d 00h 40m
INFO 2025-11-27 14:10:35,579 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:10:35,580 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.506533827100481, 'Losses/train_all_loss_mask': 0.04833277527775083, 'Losses/train_all_loss_dice': 0.7111884213629223, 'Losses/train_all_loss_iou': 0.13101038620585487, 'Losses/train_all_loss_class': 0.00029431465144080793, 'Losses/train_all_core_loss': 2.506533827100481, 'Trainer/where': 0.41904761904761906, 'Trainer/epoch': 20, 'Trainer/steps_train': 441}
INFO 2025-11-27 14:10:56,591 train_utils.py: 278: Train Epoch: [21][ 0/21] | Batch Time: 19.18 (19.18) | Data Time: 18.79 (18.79) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 35m | Losses/train_all_loss: 2.49e+00 (2.49e+00)
WARNING 2025-11-27 14:10:59,183 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:11:12,176 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:11:38,301 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:12:05,834 train_utils.py: 278: Train Epoch: [21][20/21] | Batch Time: 0.30 (4.21) | Data Time: 0.00 (3.89) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 2.38e+00 (2.48e+00)
INFO 2025-11-27 14:12:05,911 trainer.py: 955: Estimated time remaining: 00d 00h 41m
INFO 2025-11-27 14:12:05,912 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:12:05,912 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.482212407248361, 'Losses/train_all_loss_mask': 0.04580839430647237, 'Losses/train_all_loss_dice': 0.7130799321901231, 'Losses/train_all_loss_iou': 0.11392956191585177, 'Losses/train_all_loss_class': 1.0947307276216945e-06, 'Losses/train_all_core_loss': 2.482212407248361, 'Trainer/where': 0.4390476190476191, 'Trainer/epoch': 21, 'Trainer/steps_train': 462}
WARNING 2025-11-27 14:12:13,390 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:12:34,798 train_utils.py: 278: Train Epoch: [22][ 0/21] | Batch Time: 27.15 (27.15) | Data Time: 26.76 (26.76) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 37m | Losses/train_all_loss: 2.51e+00 (2.51e+00)
WARNING 2025-11-27 14:12:35,527 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:13:26,039 train_utils.py: 278: Train Epoch: [22][20/21] | Batch Time: 0.30 (3.73) | Data Time: 0.00 (3.41) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 2.44e+00 (2.52e+00)
INFO 2025-11-27 14:13:26,117 trainer.py: 955: Estimated time remaining: 00d 00h 35m
INFO 2025-11-27 14:13:26,117 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:13:26,118 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5192390396481468, 'Losses/train_all_loss_mask': 0.05162429437041283, 'Losses/train_all_loss_dice': 0.7111779195921761, 'Losses/train_all_loss_iou': 0.1275836733125505, 'Losses/train_all_loss_class': 1.8660539090001185e-07, 'Losses/train_all_core_loss': 2.5192390396481468, 'Trainer/where': 0.45904761904761904, 'Trainer/epoch': 22, 'Trainer/steps_train': 483}
WARNING 2025-11-27 14:13:41,723 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:13:47,795 train_utils.py: 278: Train Epoch: [23][ 0/21] | Batch Time: 19.70 (19.70) | Data Time: 19.30 (19.30) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 2.56e+00 (2.56e+00)
WARNING 2025-11-27 14:13:53,899 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:14:33,853 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:14:49,434 train_utils.py: 278: Train Epoch: [23][20/21] | Batch Time: 0.30 (3.87) | Data Time: 0.00 (3.55) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 39m | Losses/train_all_loss: 2.45e+00 (2.48e+00)
INFO 2025-11-27 14:14:49,509 trainer.py: 955: Estimated time remaining: 00d 00h 35m
INFO 2025-11-27 14:14:49,509 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:14:49,510 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4812820071265813, 'Losses/train_all_loss_mask': 0.043404441149461834, 'Losses/train_all_loss_dice': 0.7181752891767592, 'Losses/train_all_loss_iou': 0.10973384390984263, 'Losses/train_all_loss_class': 1.1856729101708144e-07, 'Losses/train_all_core_loss': 2.4812820071265813, 'Trainer/where': 0.47904761904761906, 'Trainer/epoch': 23, 'Trainer/steps_train': 504}
WARNING 2025-11-27 14:15:16,769 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:15:22,897 train_utils.py: 278: Train Epoch: [24][ 0/21] | Batch Time: 26.44 (26.44) | Data Time: 26.03 (26.03) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 40m | Losses/train_all_loss: 2.46e+00 (2.46e+00)
INFO 2025-11-27 14:16:26,185 train_utils.py: 278: Train Epoch: [24][20/21] | Batch Time: 14.17 (4.27) | Data Time: 13.82 (3.95) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 41m | Losses/train_all_loss: 2.49e+00 (2.49e+00)
INFO 2025-11-27 14:16:26,267 trainer.py: 955: Estimated time remaining: 00d 00h 37m
INFO 2025-11-27 14:16:26,268 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:16:26,268 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4865149089268277, 'Losses/train_all_loss_mask': 0.04774869747814678, 'Losses/train_all_loss_dice': 0.7098882028034755, 'Losses/train_all_loss_iou': 0.11810673631372906, 'Losses/train_all_loss_class': 7.402138425221289e-08, 'Losses/train_all_core_loss': 2.4865149089268277, 'Trainer/where': 0.4990476190476191, 'Trainer/epoch': 24, 'Trainer/steps_train': 525}
WARNING 2025-11-27 14:16:48,340 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:16:58,958 train_utils.py: 278: Train Epoch: [25][ 0/21] | Batch Time: 29.31 (29.31) | Data Time: 28.92 (28.92) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 41m | Losses/train_all_loss: 2.64e+00 (2.64e+00)
WARNING 2025-11-27 14:17:00,651 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:17:30,586 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:17:58,908 train_utils.py: 278: Train Epoch: [25][20/21] | Batch Time: 0.30 (4.25) | Data Time: 0.00 (3.93) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 42m | Losses/train_all_loss: 2.28e+00 (2.51e+00)
INFO 2025-11-27 14:17:58,987 trainer.py: 955: Estimated time remaining: 00d 00h 35m
INFO 2025-11-27 14:17:58,988 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:17:58,988 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5064178989047097, 'Losses/train_all_loss_mask': 0.04842135966533706, 'Losses/train_all_loss_dice': 0.7160548511005583, 'Losses/train_all_loss_iou': 0.11614423032317843, 'Losses/train_all_loss_class': 2.309429347712087e-06, 'Losses/train_all_core_loss': 2.5064178989047097, 'Trainer/where': 0.5190476190476191, 'Trainer/epoch': 25, 'Trainer/steps_train': 546}
WARNING 2025-11-27 14:18:22,183 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:18:33,842 train_utils.py: 278: Train Epoch: [26][ 0/21] | Batch Time: 33.03 (33.03) | Data Time: 32.68 (32.68) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 43m | Losses/train_all_loss: 2.86e+00 (2.86e+00)
WARNING 2025-11-27 14:18:36,317 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:18:48,130 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:18:50,408 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:18:57,312 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:19:05,342 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:19:48,757 train_utils.py: 278: Train Epoch: [26][20/21] | Batch Time: 0.30 (5.14) | Data Time: 0.00 (4.82) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 44m | Losses/train_all_loss: 2.64e+00 (2.51e+00)
INFO 2025-11-27 14:19:48,845 trainer.py: 955: Estimated time remaining: 00d 00h 41m
INFO 2025-11-27 14:19:48,846 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:19:48,846 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.5107376121339344, 'Losses/train_all_loss_mask': 0.04991853112975756, 'Losses/train_all_loss_dice': 0.7136898778733753, 'Losses/train_all_loss_iou': 0.1200578785723164, 'Losses/train_all_loss_class': 1.7448317395161012e-05, 'Losses/train_all_core_loss': 2.5107376121339344, 'Trainer/where': 0.539047619047619, 'Trainer/epoch': 26, 'Trainer/steps_train': 567}
INFO 2025-11-27 14:20:17,519 train_utils.py: 278: Train Epoch: [27][ 0/21] | Batch Time: 26.80 (26.80) | Data Time: 26.41 (26.41) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 45m | Losses/train_all_loss: 2.30e+00 (2.30e+00)
WARNING 2025-11-27 14:20:41,134 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:20:42,945 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:21:21,507 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:21:22,474 train_utils.py: 278: Train Epoch: [27][20/21] | Batch Time: 0.30 (4.37) | Data Time: 0.00 (4.05) | Mem (GB): 9.00 (8.95/9.00) | Time Elapsed: 00d 00h 46m | Losses/train_all_loss: 2.54e+00 (2.52e+00)
INFO 2025-11-27 14:21:22,550 trainer.py: 955: Estimated time remaining: 00d 00h 33m
INFO 2025-11-27 14:21:22,550 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:21:22,551 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.522238231840588, 'Losses/train_all_loss_mask': 0.04859406146265212, 'Losses/train_all_loss_dice': 0.71722240958895, 'Losses/train_all_loss_iou': 0.1276006762470518, 'Losses/train_all_loss_class': 7.362797022863227e-08, 'Losses/train_all_core_loss': 2.522238231840588, 'Trainer/where': 0.559047619047619, 'Trainer/epoch': 27, 'Trainer/steps_train': 588}
WARNING 2025-11-27 14:21:48,372 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:21:52,009 train_utils.py: 278: Train Epoch: [28][ 0/21] | Batch Time: 27.11 (27.11) | Data Time: 26.74 (26.74) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 46m | Losses/train_all_loss: 2.29e+00 (2.29e+00)
WARNING 2025-11-27 14:22:13,277 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:22:16,809 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:23:17,305 train_utils.py: 278: Train Epoch: [28][20/21] | Batch Time: 0.30 (5.35) | Data Time: 0.00 (5.03) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 48m | Losses/train_all_loss: 2.60e+00 (2.45e+00)
INFO 2025-11-27 14:23:17,378 trainer.py: 955: Estimated time remaining: 00d 00h 39m
INFO 2025-11-27 14:23:17,378 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:23:17,378 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4525127637953985, 'Losses/train_all_loss_mask': 0.046373240561002775, 'Losses/train_all_loss_dice': 0.700204732872191, 'Losses/train_all_loss_iou': 0.12001666852406093, 'Losses/train_all_loss_class': 1.5743624008428864e-05, 'Losses/train_all_core_loss': 2.4525127637953985, 'Trainer/where': 0.579047619047619, 'Trainer/epoch': 28, 'Trainer/steps_train': 609}
INFO 2025-11-27 14:23:47,856 train_utils.py: 278: Train Epoch: [29][ 0/21] | Batch Time: 28.63 (28.63) | Data Time: 28.27 (28.27) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 48m | Losses/train_all_loss: 2.58e+00 (2.58e+00)
WARNING 2025-11-27 14:24:03,958 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:24:39,664 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:24:45,553 train_utils.py: 278: Train Epoch: [29][20/21] | Batch Time: 15.23 (4.11) | Data Time: 14.85 (3.80) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 49m | Losses/train_all_loss: 2.40e+00 (2.50e+00)
INFO 2025-11-27 14:24:45,638 trainer.py: 955: Estimated time remaining: 00d 00h 28m
INFO 2025-11-27 14:24:45,638 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:24:45,638 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4965846879141673, 'Losses/train_all_loss_mask': 0.047928152251101676, 'Losses/train_all_loss_dice': 0.7132940065293085, 'Losses/train_all_loss_iou': 0.11702881416394598, 'Losses/train_all_loss_class': 3.311482487503742e-05, 'Losses/train_all_core_loss': 2.4965846879141673, 'Trainer/where': 0.599047619047619, 'Trainer/epoch': 29, 'Trainer/steps_train': 630}
INFO 2025-11-27 14:25:02,112 train_utils.py: 278: Train Epoch: [30][ 0/21] | Batch Time: 13.13 (13.13) | Data Time: 12.68 (12.68) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 49m | Losses/train_all_loss: 2.40e+00 (2.40e+00)
WARNING 2025-11-27 14:25:08,025 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:25:16,080 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:25:24,380 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:25:33,518 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:25:42,138 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:26:31,909 train_utils.py: 278: Train Epoch: [30][20/21] | Batch Time: 0.30 (4.90) | Data Time: 0.00 (4.58) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 51m | Losses/train_all_loss: 2.53e+00 (2.45e+00)
INFO 2025-11-27 14:26:31,995 trainer.py: 955: Estimated time remaining: 00d 00h 32m
INFO 2025-11-27 14:26:31,996 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:26:31,996 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4466106664566767, 'Losses/train_all_loss_mask': 0.04514096083030814, 'Losses/train_all_loss_dice': 0.7015724522726876, 'Losses/train_all_loss_iou': 0.11618507688953764, 'Losses/train_all_loss_class': 3.4425534306336574e-06, 'Losses/train_all_core_loss': 2.4466106664566767, 'Trainer/where': 0.6190476190476191, 'Trainer/epoch': 30, 'Trainer/steps_train': 651}
INFO 2025-11-27 14:26:47,477 train_utils.py: 278: Train Epoch: [31][ 0/21] | Batch Time: 13.58 (13.58) | Data Time: 13.22 (13.22) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 51m | Losses/train_all_loss: 2.17e+00 (2.17e+00)
WARNING 2025-11-27 14:26:51,802 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:28:14,145 train_utils.py: 278: Train Epoch: [31][20/21] | Batch Time: 22.57 (4.77) | Data Time: 22.20 (4.45) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 52m | Losses/train_all_loss: 2.35e+00 (2.42e+00)
INFO 2025-11-27 14:28:14,211 trainer.py: 955: Estimated time remaining: 00d 00h 30m
INFO 2025-11-27 14:28:14,211 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:28:14,211 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4215080283937, 'Losses/train_all_loss_mask': 0.044536334418115164, 'Losses/train_all_loss_dice': 0.6922936950411115, 'Losses/train_all_loss_iou': 0.12194522470235825, 'Losses/train_all_loss_class': 4.9044595992885403e-08, 'Losses/train_all_core_loss': 2.4215080283937, 'Trainer/where': 0.6390476190476191, 'Trainer/epoch': 31, 'Trainer/steps_train': 672}
INFO 2025-11-27 14:28:38,382 train_utils.py: 278: Train Epoch: [32][ 0/21] | Batch Time: 22.38 (22.38) | Data Time: 21.98 (21.98) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 53m | Losses/train_all_loss: 2.49e+00 (2.49e+00)
WARNING 2025-11-27 14:28:52,501 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:29:43,445 train_utils.py: 278: Train Epoch: [32][20/21] | Batch Time: 0.30 (4.16) | Data Time: 0.00 (3.85) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 54m | Losses/train_all_loss: 2.44e+00 (2.44e+00)
INFO 2025-11-27 14:29:43,518 trainer.py: 955: Estimated time remaining: 00d 00h 24m
INFO 2025-11-27 14:29:43,518 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:29:43,519 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.443525711695353, 'Losses/train_all_loss_mask': 0.05274368893532526, 'Losses/train_all_loss_dice': 0.6859090612048194, 'Losses/train_all_loss_iou': 0.1220663468397799, 'Losses/train_all_loss_class': 1.3744648054941117e-05, 'Losses/train_all_core_loss': 2.443525711695353, 'Trainer/where': 0.659047619047619, 'Trainer/epoch': 32, 'Trainer/steps_train': 693}
INFO 2025-11-27 14:30:10,848 train_utils.py: 278: Train Epoch: [33][ 0/21] | Batch Time: 25.54 (25.54) | Data Time: 25.17 (25.17) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 54m | Losses/train_all_loss: 2.55e+00 (2.55e+00)
INFO 2025-11-27 14:31:25,144 train_utils.py: 278: Train Epoch: [33][20/21] | Batch Time: 0.30 (4.75) | Data Time: 0.00 (4.43) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 56m | Losses/train_all_loss: 2.25e+00 (2.45e+00)
INFO 2025-11-27 14:31:25,215 trainer.py: 955: Estimated time remaining: 00d 00h 26m
INFO 2025-11-27 14:31:25,215 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:31:25,216 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4450548603421165, 'Losses/train_all_loss_mask': 0.04779800879103797, 'Losses/train_all_loss_dice': 0.6972890382721311, 'Losses/train_all_loss_iou': 0.11419759229535148, 'Losses/train_all_loss_class': 1.0743157980349267e-07, 'Losses/train_all_core_loss': 2.4450548603421165, 'Trainer/where': 0.679047619047619, 'Trainer/epoch': 33, 'Trainer/steps_train': 714}
INFO 2025-11-27 14:32:00,256 train_utils.py: 278: Train Epoch: [34][ 0/21] | Batch Time: 33.28 (33.28) | Data Time: 32.93 (32.93) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 56m | Losses/train_all_loss: 2.32e+00 (2.32e+00)
WARNING 2025-11-27 14:32:17,187 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:32:41,921 train_utils.py: 278: Train Epoch: [34][20/21] | Batch Time: 0.30 (3.57) | Data Time: 0.00 (3.26) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 57m | Losses/train_all_loss: 2.32e+00 (2.44e+00)
INFO 2025-11-27 14:32:41,999 trainer.py: 955: Estimated time remaining: 00d 00h 18m
INFO 2025-11-27 14:32:42,000 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:32:42,000 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4396410442533947, 'Losses/train_all_loss_mask': 0.04688818468934014, 'Losses/train_all_loss_dice': 0.6976642239661444, 'Losses/train_all_loss_iou': 0.1121958236963976, 'Losses/train_all_loss_class': 1.158948473336556e-05, 'Losses/train_all_core_loss': 2.4396410442533947, 'Trainer/where': 0.699047619047619, 'Trainer/epoch': 34, 'Trainer/steps_train': 735}
WARNING 2025-11-27 14:32:48,899 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:32:58,651 train_utils.py: 278: Train Epoch: [35][ 0/21] | Batch Time: 12.87 (12.87) | Data Time: 12.50 (12.50) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 57m | Losses/train_all_loss: 2.39e+00 (2.39e+00)
WARNING 2025-11-27 14:33:42,867 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:34:15,006 train_utils.py: 278: Train Epoch: [35][20/21] | Batch Time: 13.26 (4.25) | Data Time: 12.90 (3.92) | Mem (GB): 9.00 (8.95/9.00) | Time Elapsed: 00d 00h 58m | Losses/train_all_loss: 2.26e+00 (2.45e+00)
INFO 2025-11-27 14:34:15,087 trainer.py: 955: Estimated time remaining: 00d 00h 20m
INFO 2025-11-27 14:34:15,088 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:34:15,088 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4525170099167597, 'Losses/train_all_loss_mask': 0.04831129135120483, 'Losses/train_all_loss_dice': 0.6942723677271888, 'Losses/train_all_loss_iou': 0.1281430142975989, 'Losses/train_all_loss_class': 3.847640754154706e-07, 'Losses/train_all_core_loss': 2.4525170099167597, 'Trainer/where': 0.7190476190476189, 'Trainer/epoch': 35, 'Trainer/steps_train': 756}
INFO 2025-11-27 14:34:39,324 train_utils.py: 278: Train Epoch: [36][ 0/21] | Batch Time: 22.17 (22.17) | Data Time: 21.78 (21.78) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 00h 59m | Losses/train_all_loss: 2.39e+00 (2.39e+00)
WARNING 2025-11-27 14:34:39,958 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:35:20,184 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:35:34,758 train_utils.py: 278: Train Epoch: [36][20/21] | Batch Time: 0.29 (3.70) | Data Time: 0.00 (3.36) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 00m | Losses/train_all_loss: 2.45e+00 (2.44e+00)
INFO 2025-11-27 14:35:34,847 trainer.py: 955: Estimated time remaining: 00d 00h 16m
INFO 2025-11-27 14:35:34,848 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:35:34,848 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.443554844175066, 'Losses/train_all_loss_mask': 0.046576764789365586, 'Losses/train_all_loss_dice': 0.6947431706246876, 'Losses/train_all_loss_iou': 0.12643758420433318, 'Losses/train_all_loss_class': 3.965453847353832e-06, 'Losses/train_all_core_loss': 2.443554844175066, 'Trainer/where': 0.739047619047619, 'Trainer/epoch': 36, 'Trainer/steps_train': 777}
INFO 2025-11-27 14:36:19,448 train_utils.py: 278: Train Epoch: [37][ 0/21] | Batch Time: 42.82 (42.82) | Data Time: 42.43 (42.43) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 01m | Losses/train_all_loss: 2.48e+00 (2.48e+00)
WARNING 2025-11-27 14:36:26,738 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:36:33,098 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:37:06,731 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:37:12,994 train_utils.py: 278: Train Epoch: [37][20/21] | Batch Time: 0.30 (4.59) | Data Time: 0.00 (4.28) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 01m | Losses/train_all_loss: 2.38e+00 (2.42e+00)
INFO 2025-11-27 14:37:13,071 trainer.py: 955: Estimated time remaining: 00d 00h 19m
INFO 2025-11-27 14:37:13,071 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:37:13,071 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.423566523052397, 'Losses/train_all_loss_mask': 0.04895835742354393, 'Losses/train_all_loss_dice': 0.6810087958971659, 'Losses/train_all_loss_iou': 0.13574193027757464, 'Losses/train_all_loss_class': 6.421494654806374e-06, 'Losses/train_all_core_loss': 2.423566523052397, 'Trainer/where': 0.759047619047619, 'Trainer/epoch': 37, 'Trainer/steps_train': 798}
INFO 2025-11-27 14:37:59,039 train_utils.py: 278: Train Epoch: [38][ 0/21] | Batch Time: 43.93 (43.93) | Data Time: 43.57 (43.57) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 02m | Losses/train_all_loss: 2.34e+00 (2.34e+00)
WARNING 2025-11-27 14:38:19,406 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:39:01,022 train_utils.py: 278: Train Epoch: [38][20/21] | Batch Time: 0.30 (5.04) | Data Time: 0.00 (4.72) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 03m | Losses/train_all_loss: 2.50e+00 (2.40e+00)
INFO 2025-11-27 14:39:01,100 trainer.py: 955: Estimated time remaining: 00d 00h 19m
INFO 2025-11-27 14:39:01,101 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:39:01,101 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.3997089749290827, 'Losses/train_all_loss_mask': 0.04979005979285354, 'Losses/train_all_loss_dice': 0.673555504708063, 'Losses/train_all_loss_iou': 0.13008337290514083, 'Losses/train_all_loss_class': 8.785257620613245e-06, 'Losses/train_all_core_loss': 2.3997089749290827, 'Trainer/where': 0.779047619047619, 'Trainer/epoch': 38, 'Trainer/steps_train': 819}
WARNING 2025-11-27 14:39:15,877 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:39:23,151 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:39:44,670 train_utils.py: 278: Train Epoch: [39][ 0/21] | Batch Time: 41.51 (41.51) | Data Time: 41.14 (41.14) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 04m | Losses/train_all_loss: 2.44e+00 (2.44e+00)
WARNING 2025-11-27 14:39:49,957 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:40:39,840 train_utils.py: 278: Train Epoch: [39][20/21] | Batch Time: 0.30 (4.60) | Data Time: 0.00 (4.29) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 05m | Losses/train_all_loss: 2.49e+00 (2.45e+00)
INFO 2025-11-27 14:40:40,007 trainer.py: 955: Estimated time remaining: 00d 00h 16m
INFO 2025-11-27 14:40:40,008 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:40:40,008 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.445342915398734, 'Losses/train_all_loss_mask': 0.047657175965252374, 'Losses/train_all_loss_dice': 0.6964481813567025, 'Losses/train_all_loss_iou': 0.11769799178554899, 'Losses/train_all_loss_class': 1.451695895158626e-05, 'Losses/train_all_core_loss': 2.445342915398734, 'Trainer/where': 0.799047619047619, 'Trainer/epoch': 39, 'Trainer/steps_train': 840}
WARNING 2025-11-27 14:41:11,483 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:41:21,324 train_utils.py: 278: Train Epoch: [40][ 0/21] | Batch Time: 30.02 (30.02) | Data Time: 29.64 (29.64) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 06m | Losses/train_all_loss: 2.16e+00 (2.16e+00)
WARNING 2025-11-27 14:41:49,974 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:42:21,151 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:42:22,531 train_utils.py: 278: Train Epoch: [40][20/21] | Batch Time: 0.30 (4.34) | Data Time: 0.00 (3.25) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 07m | Losses/train_all_loss: 2.32e+00 (2.43e+00)
INFO 2025-11-27 14:42:22,609 trainer.py: 955: Estimated time remaining: 00d 00h 13m
INFO 2025-11-27 14:42:22,610 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:42:22,610 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4281749725341797, 'Losses/train_all_loss_mask': 0.04650077649525234, 'Losses/train_all_loss_dice': 0.6912958792277745, 'Losses/train_all_loss_iou': 0.12178234294766471, 'Losses/train_all_loss_class': 1.1060667406401874e-06, 'Losses/train_all_core_loss': 2.4281749725341797, 'Trainer/where': 0.819047619047619, 'Trainer/epoch': 40, 'Trainer/steps_train': 861}
WARNING 2025-11-27 14:42:27,864 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:42:38,106 train_utils.py: 278: Train Epoch: [41][ 0/21] | Batch Time: 12.94 (12.94) | Data Time: 12.57 (12.57) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 07m | Losses/train_all_loss: 2.51e+00 (2.51e+00)
WARNING 2025-11-27 14:43:04,290 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:43:40,018 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:43:50,810 train_utils.py: 278: Train Epoch: [41][20/21] | Batch Time: 0.30 (4.08) | Data Time: 0.00 (3.76) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 08m | Losses/train_all_loss: 2.65e+00 (2.46e+00)
INFO 2025-11-27 14:43:50,883 trainer.py: 955: Estimated time remaining: 00d 00h 11m
INFO 2025-11-27 14:43:50,883 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:43:50,884 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.456038304737636, 'Losses/train_all_loss_mask': 0.05073597024948824, 'Losses/train_all_loss_dice': 0.6881945814405169, 'Losses/train_all_loss_iou': 0.13776869291350954, 'Losses/train_all_loss_class': 6.012524812418736e-06, 'Losses/train_all_core_loss': 2.456038304737636, 'Trainer/where': 0.8390476190476189, 'Trainer/epoch': 41, 'Trainer/steps_train': 882}
INFO 2025-11-27 14:44:03,336 train_utils.py: 278: Train Epoch: [42][ 0/21] | Batch Time: 10.62 (10.62) | Data Time: 10.27 (10.27) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 08m | Losses/train_all_loss: 2.26e+00 (2.26e+00)
WARNING 2025-11-27 14:44:05,561 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:44:20,905 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:44:48,780 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:44:49,438 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:45:20,738 train_utils.py: 278: Train Epoch: [42][20/21] | Batch Time: 0.30 (4.19) | Data Time: 0.00 (3.87) | Mem (GB): 9.00 (8.95/9.00) | Time Elapsed: 00d 01h 10m | Losses/train_all_loss: 2.36e+00 (2.41e+00)
INFO 2025-11-27 14:45:20,817 trainer.py: 955: Estimated time remaining: 00d 00h 10m
INFO 2025-11-27 14:45:20,818 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:45:20,818 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4050417627607072, 'Losses/train_all_loss_mask': 0.04735881604609035, 'Losses/train_all_loss_dice': 0.683203379313151, 'Losses/train_all_loss_iou': 0.11862861116727193, 'Losses/train_all_loss_class': 8.922427387101731e-06, 'Losses/train_all_core_loss': 2.4050417627607072, 'Trainer/where': 0.859047619047619, 'Trainer/epoch': 42, 'Trainer/steps_train': 903}
WARNING 2025-11-27 14:45:41,297 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:45:43,016 train_utils.py: 278: Train Epoch: [43][ 0/21] | Batch Time: 19.52 (19.52) | Data Time: 19.16 (19.16) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 10m | Losses/train_all_loss: 2.35e+00 (2.35e+00)
INFO 2025-11-27 14:46:55,813 train_utils.py: 278: Train Epoch: [43][20/21] | Batch Time: 0.30 (4.40) | Data Time: 0.00 (4.08) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 11m | Losses/train_all_loss: 2.60e+00 (2.47e+00)
INFO 2025-11-27 14:46:55,891 trainer.py: 955: Estimated time remaining: 00d 00h 09m
INFO 2025-11-27 14:46:55,892 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:46:55,892 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4706415789467946, 'Losses/train_all_loss_mask': 0.04813692789702188, 'Losses/train_all_loss_dice': 0.7042546499343145, 'Losses/train_all_loss_iou': 0.11719289067245665, 'Losses/train_all_loss_class': 1.475715674057835e-07, 'Losses/train_all_core_loss': 2.4706415789467946, 'Trainer/where': 0.879047619047619, 'Trainer/epoch': 43, 'Trainer/steps_train': 924}
INFO 2025-11-27 14:47:17,621 train_utils.py: 278: Train Epoch: [44][ 0/21] | Batch Time: 18.73 (18.73) | Data Time: 18.32 (18.32) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 12m | Losses/train_all_loss: 2.63e+00 (2.63e+00)
WARNING 2025-11-27 14:47:19,168 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:48:23,136 train_utils.py: 278: Train Epoch: [44][20/21] | Batch Time: 1.48 (4.01) | Data Time: 1.18 (3.69) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 13m | Losses/train_all_loss: 2.46e+00 (2.44e+00)
INFO 2025-11-27 14:48:23,211 trainer.py: 955: Estimated time remaining: 00d 00h 07m
INFO 2025-11-27 14:48:23,212 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:48:23,212 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4426431882949102, 'Losses/train_all_loss_mask': 0.047962675314574016, 'Losses/train_all_loss_dice': 0.6946406506356739, 'Losses/train_all_loss_iou': 0.11890738634836107, 'Losses/train_all_loss_class': 4.6167865219715054e-07, 'Losses/train_all_core_loss': 2.4426431882949102, 'Trainer/where': 0.899047619047619, 'Trainer/epoch': 44, 'Trainer/steps_train': 945}
WARNING 2025-11-27 14:48:32,120 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:48:49,288 train_utils.py: 278: Train Epoch: [45][ 0/21] | Batch Time: 22.44 (22.44) | Data Time: 22.06 (22.06) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 13m | Losses/train_all_loss: 2.65e+00 (2.65e+00)
WARNING 2025-11-27 14:49:16,670 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:50:11,498 train_utils.py: 278: Train Epoch: [45][20/21] | Batch Time: 0.29 (4.98) | Data Time: 0.00 (4.66) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 14m | Losses/train_all_loss: 2.38e+00 (2.41e+00)
INFO 2025-11-27 14:50:11,584 trainer.py: 955: Estimated time remaining: 00d 00h 06m
INFO 2025-11-27 14:50:11,584 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:50:11,584 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4139222985222224, 'Losses/train_all_loss_mask': 0.04596925447029727, 'Losses/train_all_loss_dice': 0.6857471693129766, 'Losses/train_all_loss_iou': 0.1268253035488583, 'Losses/train_all_loss_class': 9.227162990814508e-06, 'Losses/train_all_core_loss': 2.4139222985222224, 'Trainer/where': 0.919047619047619, 'Trainer/epoch': 45, 'Trainer/steps_train': 966}
WARNING 2025-11-27 14:50:33,037 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:50:35,651 train_utils.py: 278: Train Epoch: [46][ 0/21] | Batch Time: 22.22 (22.22) | Data Time: 21.80 (21.80) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 15m | Losses/train_all_loss: 2.59e+00 (2.59e+00)
WARNING 2025-11-27 14:50:38,300 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
WARNING 2025-11-27 14:51:08,780 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:51:52,145 train_utils.py: 278: Train Epoch: [46][20/21] | Batch Time: 10.53 (4.70) | Data Time: 10.15 (4.38) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 16m | Losses/train_all_loss: 2.16e+00 (2.48e+00)
INFO 2025-11-27 14:51:52,229 trainer.py: 955: Estimated time remaining: 00d 00h 04m
INFO 2025-11-27 14:51:52,230 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:51:52,230 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.483660720643543, 'Losses/train_all_loss_mask': 0.04843181992570559, 'Losses/train_all_loss_dice': 0.7064856347583589, 'Losses/train_all_loss_iou': 0.12204271448510033, 'Losses/train_all_loss_class': 2.003383870114027e-06, 'Losses/train_all_core_loss': 2.483660720643543, 'Trainer/where': 0.939047619047619, 'Trainer/epoch': 46, 'Trainer/steps_train': 987}
INFO 2025-11-27 14:52:32,138 train_utils.py: 278: Train Epoch: [47][ 0/21] | Batch Time: 38.04 (38.04) | Data Time: 37.65 (37.65) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 17m | Losses/train_all_loss: 2.30e+00 (2.30e+00)
INFO 2025-11-27 14:53:21,730 train_utils.py: 278: Train Epoch: [47][20/21] | Batch Time: 1.25 (4.17) | Data Time: 0.96 (3.86) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 18m | Losses/train_all_loss: 2.66e+00 (2.41e+00)
INFO 2025-11-27 14:53:21,803 trainer.py: 955: Estimated time remaining: 00d 00h 02m
INFO 2025-11-27 14:53:21,803 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:53:21,804 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4114766234443303, 'Losses/train_all_loss_mask': 0.046945225624811085, 'Losses/train_all_loss_dice': 0.6875007294473194, 'Losses/train_all_loss_iou': 0.11423420515798387, 'Losses/train_all_loss_class': 1.4093948411166476e-05, 'Losses/train_all_core_loss': 2.4114766234443303, 'Trainer/where': 0.9590476190476189, 'Trainer/epoch': 47, 'Trainer/steps_train': 1008}
INFO 2025-11-27 14:53:59,563 train_utils.py: 278: Train Epoch: [48][ 0/21] | Batch Time: 35.69 (35.69) | Data Time: 35.32 (35.32) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 18m | Losses/train_all_loss: 2.70e+00 (2.70e+00)
WARNING 2025-11-27 14:54:05,355 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:54:57,815 train_utils.py: 278: Train Epoch: [48][20/21] | Batch Time: 0.30 (4.47) | Data Time: 0.00 (4.16) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 19m | Losses/train_all_loss: 2.58e+00 (2.42e+00)
INFO 2025-11-27 14:54:57,894 trainer.py: 955: Estimated time remaining: 00d 00h 01m
INFO 2025-11-27 14:54:57,895 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:54:57,895 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.423987343197777, 'Losses/train_all_loss_mask': 0.04910745258842196, 'Losses/train_all_loss_dice': 0.6846404132388887, 'Losses/train_all_loss_iou': 0.12449867296076957, 'Losses/train_all_loss_class': 3.0138915856656046e-05, 'Losses/train_all_core_loss': 2.423987343197777, 'Trainer/where': 0.9790476190476189, 'Trainer/epoch': 48, 'Trainer/steps_train': 1029}
INFO 2025-11-27 14:55:22,528 train_utils.py: 278: Train Epoch: [49][ 0/21] | Batch Time: 22.74 (22.74) | Data Time: 22.38 (22.38) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 20m | Losses/train_all_loss: 2.40e+00 (2.40e+00)
WARNING 2025-11-27 14:55:26,533 transforms.py: 418: Skip RandomAffine for zero-area mask in first frame after 2 tentatives
INFO 2025-11-27 14:56:23,854 train_utils.py: 278: Train Epoch: [49][20/21] | Batch Time: 0.30 (4.00) | Data Time: 0.00 (3.68) | Mem (GB): 9.00 (9.00/9.00) | Time Elapsed: 00d 01h 21m | Losses/train_all_loss: 2.34e+00 (2.43e+00)
INFO 2025-11-27 14:56:23,928 trainer.py: 955: Estimated time remaining: 00d 00h 00m
INFO 2025-11-27 14:56:23,929 trainer.py: 897: Synchronizing meters
INFO 2025-11-27 14:56:23,929 trainer.py: 835: Losses and meters: {'Losses/train_all_loss': 2.4261477561224076, 'Losses/train_all_loss_mask': 0.04970095111500649, 'Losses/train_all_loss_dice': 0.6815977380389259, 'Losses/train_all_loss_iou': 0.13284412168321155, 'Losses/train_all_loss_class': 5.660201196929411e-06, 'Losses/train_all_core_loss': 2.4261477561224076, 'Trainer/where': 0.999047619047619, 'Trainer/epoch': 49, 'Trainer/steps_train': 1050}

============================================================
Training Complete!
Output: /scratch/user/shubhammhaske/vfm_project
============================================================

==============================================
Complete!
Exit: 0
End: Thu Nov 27 14:57:13 CST 2025
Output: finetune_logs/path_sam2_ctranspath-17213024
==============================================

Running evaluation on: finetune_logs/path_sam2_ctranspath-17213024/checkpoints/checkpoint_50.pt
Using Nvidia CUDA backend.
================================================================================
Starting quantitative evaluation...
  SAM Config:     configs/sam2.1/sam2.1_hiera_l.yaml
  SAM Checkpoint: /scratch/user/shubhammhaske/vfm_project/finetune_logs/path_sam2_ctranspath-17213024/checkpoints/checkpoint_50.pt
  CLIP Prompts:   /scratch/user/shubhammhaske/vfm_project/configs/prompts/hard_coded_prompts_v2.json
  Output Dir:     /scratch/user/shubhammhaske/vfm_project/results/path_sam2_ctp_eval_17213024
================================================================================
Using Nvidia CUDA backend.
Using device: cuda
Loading models...
